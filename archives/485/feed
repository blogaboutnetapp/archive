<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	>
<channel>
	<title>Комментарии к записи: Тестирование с помощью программы IOmeter</title>
	<atom:link href="http://blog.aboutnetapp.ru/archives/485/feed" rel="self" type="application/rss+xml" />
	<link>http://blog.aboutnetapp.ru/archives/485</link>
	<description>Системы хранения данных как предмет разговора</description>
	<pubDate>Wed, 07 Apr 2021 12:06:53 +0000</pubDate>
	<generator>http://wordpress.org/?v=2.6</generator>
		<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/485#comment-370</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Thu, 15 Apr 2010 07:35:45 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=485#comment-370</guid>
		<description>&gt; То есть если мы будем проводить тест на random-доступ на одном и том же носителе результат все время будет одним и тем же?, но по мере увеличения фрагментации в результате неоднократного копирования перемещения и удаления файлов, работы приложений, на данном носителе реальная производительность с реально размещенными на носителе данными понизится т.е время доступа увеличится.

Нет.
Принято считать, что для современных многозадачных OS и распространненых приложений, таких как OLTP-базы, характер дисковой нагрузки сегодня является преимущественно рандомным. 
"Есть мнение", что в случае рандомного доступа несущественно то, насколько последовательно расположены на диске данные, если читают и пишут их все равно в случайном порядке. "Случайное расположение помноженное на случайный порядок чтения-записи не дает "случайное в квадрате", оно по прежнему остается просто случайным"
Отсутствие фрагментации улучшает характеристики доступа в основном для данных, которые читаются и пишутся последовательно, а это относительно малораспространенный набор задач.
Более того, и об этом я уже тоже писал, в ряде случаев, на современных OS и современных производительных системах хранения с большим и "умным" кэшем, фрагментация даже в условиях последовательного доступа мало влияет на характеристики производительности.

Так это или нет - существуют разные мнения. Задача, поверьте, совсем не так проста, как кажется.
Но это все, увы, пока только чужие мнения. Лично своего, основанного на каких-то моих собствнных экспериментах я пока не сложил.
Главная сложность - в методологии тестирования. Я пока такую, чтобы она устраивала и меня и точность, не разработал.</description>
		<content:encoded><![CDATA[<p>> То есть если мы будем проводить тест на random-доступ на одном и том же носителе результат все время будет одним и тем же?, но по мере увеличения фрагментации в результате неоднократного копирования перемещения и удаления файлов, работы приложений, на данном носителе реальная производительность с реально размещенными на носителе данными понизится т.е время доступа увеличится.</p>
<p>Нет.<br />
Принято считать, что для современных многозадачных OS и распространненых приложений, таких как OLTP-базы, характер дисковой нагрузки сегодня является преимущественно рандомным.<br />
&#8220;Есть мнение&#8221;, что в случае рандомного доступа несущественно то, насколько последовательно расположены на диске данные, если читают и пишут их все равно в случайном порядке. &#8220;Случайное расположение помноженное на случайный порядок чтения-записи не дает &#8220;случайное в квадрате&#8221;, оно по прежнему остается просто случайным&#8221;<br />
Отсутствие фрагментации улучшает характеристики доступа в основном для данных, которые читаются и пишутся последовательно, а это относительно малораспространенный набор задач.<br />
Более того, и об этом я уже тоже писал, в ряде случаев, на современных OS и современных производительных системах хранения с большим и &#8220;умным&#8221; кэшем, фрагментация даже в условиях последовательного доступа мало влияет на характеристики производительности.</p>
<p>Так это или нет - существуют разные мнения. Задача, поверьте, совсем не так проста, как кажется.<br />
Но это все, увы, пока только чужие мнения. Лично своего, основанного на каких-то моих собствнных экспериментах я пока не сложил.<br />
Главная сложность - в методологии тестирования. Я пока такую, чтобы она устраивала и меня и точность, не разработал.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: haver</title>
		<link>http://blog.aboutnetapp.ru/archives/485#comment-369</link>
		<dc:creator>haver</dc:creator>
		<pubDate>Wed, 14 Apr 2010 20:01:31 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=485#comment-369</guid>
		<description>То есть если мы будем проводить тест на random-доступ на одном и том же носителе результат все время будет одним и тем же?, но по мере увеличения фрагментации в результате неоднократного копирования перемещения и удаления файлов, работы приложений,  на данном носителе реальная производительность с реально размещенными на носителе данными понизится т.е время доступа увеличится.
А тест на случайный доступ будет по прежнему показывать то же значение?
Если я хочу сравнить между собой поведение нескольких разных носителей в условиях увеличения фрагментации, просто по показателям времени случайного доступа смогу ли я прогнозировать поведение их при реальной фрагментации?
?? задача измерить скорость доступа к конкретным данным при реальной фрагментации неосуществима?</description>
		<content:encoded><![CDATA[<p>То есть если мы будем проводить тест на random-доступ на одном и том же носителе результат все время будет одним и тем же?, но по мере увеличения фрагментации в результате неоднократного копирования перемещения и удаления файлов, работы приложений,  на данном носителе реальная производительность с реально размещенными на носителе данными понизится т.е время доступа увеличится.<br />
А тест на случайный доступ будет по прежнему показывать то же значение?<br />
Если я хочу сравнить между собой поведение нескольких разных носителей в условиях увеличения фрагментации, просто по показателям времени случайного доступа смогу ли я прогнозировать поведение их при реальной фрагментации?<br />
?? задача измерить скорость доступа к конкретным данным при реальной фрагментации неосуществима?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/485#comment-367</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Mon, 12 Apr 2010 09:03:31 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=485#comment-367</guid>
		<description>&gt; Возможно ли с помощью IOmeter имитировать высокую фрагментацию

Вопрос с фрагментацией на самом деле непростой. На этот счет существют два разных мнения, и я пока не присоединился ни к одному из них.
Например Alex McDonald (http://blog.aboutnetapp.ru/archives/455) разумно утверждает, что величина фрагментированности не играет существенной роли в случае random-доступа.
Независимо от того, лежит ли ваш файл цельно и последовательно, или разбросан по диску, если считывание с него будет производиться случайным образом (а именно random access нас в первую очередь должен интересовать, задачи последовательного чтения-записи это довольно узкочастные на сегодня области применения, типа считывания-записи логов БД или видео-аудио запись), то random-доступ "помноженный" на random-размещение файла (фрагментация) не дает "рандом в квадрате", он остается все тем же случайным доступом.
Теоретически, результат random access к фрагментированному файлу не должен сильно отличаться от такого же random access к нефрагментированному.</description>
		<content:encoded><![CDATA[<p>> Возможно ли с помощью IOmeter имитировать высокую фрагментацию</p>
<p>Вопрос с фрагментацией на самом деле непростой. На этот счет существют два разных мнения, и я пока не присоединился ни к одному из них.<br />
Например Alex McDonald (http://blog.aboutnetapp.ru/archives/455) разумно утверждает, что величина фрагментированности не играет существенной роли в случае random-доступа.<br />
Независимо от того, лежит ли ваш файл цельно и последовательно, или разбросан по диску, если считывание с него будет производиться случайным образом (а именно random access нас в первую очередь должен интересовать, задачи последовательного чтения-записи это довольно узкочастные на сегодня области применения, типа считывания-записи логов БД или видео-аудио запись), то random-доступ &#8220;помноженный&#8221; на random-размещение файла (фрагментация) не дает &#8220;рандом в квадрате&#8221;, он остается все тем же случайным доступом.<br />
Теоретически, результат random access к фрагментированному файлу не должен сильно отличаться от такого же random access к нефрагментированному.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: haver</title>
		<link>http://blog.aboutnetapp.ru/archives/485#comment-366</link>
		<dc:creator>haver</dc:creator>
		<pubDate>Mon, 12 Apr 2010 07:03:45 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=485#comment-366</guid>
		<description>Возможно ли с помощью IOmeter имитировать высокую фрагментацию, может быть есть готовые профили?
Не силен в английском чтобы поискать методики в англоязычном интерте.</description>
		<content:encoded><![CDATA[<p>Возможно ли с помощью IOmeter имитировать высокую фрагментацию, может быть есть готовые профили?<br />
Не силен в английском чтобы поискать методики в англоязычном интерте.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
