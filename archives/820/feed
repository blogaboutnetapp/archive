<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	>
<channel>
	<title>Комментарии к записи: Правда ли что производительность хранилища NetApp падает со временем из-за фрагментации?</title>
	<atom:link href="http://blog.aboutnetapp.ru/archives/820/feed" rel="self" type="application/rss+xml" />
	<link>http://blog.aboutnetapp.ru/archives/820</link>
	<description>Системы хранения данных как предмет разговора</description>
	<pubDate>Wed, 07 Apr 2021 12:05:59 +0000</pubDate>
	<generator>http://wordpress.org/?v=2.6</generator>
		<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1159</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Mon, 21 Feb 2011 17:48:03 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1159</guid>
		<description>&gt; Почитайте внимательно про wafl

Спасибо за предложение "почитать про WAFL". Я тронут :)
Пожалуй вы первый в этом блоге мне такое предложили ;) Надеюсь это было от чистого сердца. ;)</description>
		<content:encoded><![CDATA[<p>> Почитайте внимательно про wafl</p>
<p>Спасибо за предложение &#8220;почитать про WAFL&#8221;. Я тронут :)<br />
Пожалуй вы первый в этом блоге мне такое предложили ;) Надеюсь это было от чистого сердца. ;)</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: Allilya</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1158</link>
		<dc:creator>Allilya</dc:creator>
		<pubDate>Mon, 21 Feb 2011 17:42:32 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1158</guid>
		<description>panvartan:
А дело не в кеше. Почитайте внимательно про wafl, все плюсы и минусы будут ясны, как разберетесь в принципах!
Если объем раздела на котором тестировали был меньше полного объема дисков, то тест на рандом запись при wafl должен показывать скорость линейной записи на raid6! Почему так? Ну очевидно, данные пишутся туда, куда проще, т.е. в свободное место дисков (незадействованное, и явно что lun не ограничивает) и пофиг сколько потоков и что они рандом, все пишется последовательно в свободное место. Попутно создается таблица соответствия "виртуальных" и "реальных" секторов. Как "свободное" место заканчивается, если под lun'ы было отведено не более половины места, значит то "физическое" место уже свободно и туда продолжается запись потоком и т.д. Вот если сделать рандом тест на объем равный физическому месту на диске, то после записи первого полного объема (назовем инициализацией) начнется настоящая рандом запись со всеми вытекающими... при этом даже линейная запись на wafl привратится в рандом. О ужас. Вообщем синтетику сделать, чтобы netapp был в попе видимо не сложно. Куда интересней, как в реальной жизни он поведет.</description>
		<content:encoded><![CDATA[<p>panvartan:<br />
А дело не в кеше. Почитайте внимательно про wafl, все плюсы и минусы будут ясны, как разберетесь в принципах!<br />
Если объем раздела на котором тестировали был меньше полного объема дисков, то тест на рандом запись при wafl должен показывать скорость линейной записи на raid6! Почему так? Ну очевидно, данные пишутся туда, куда проще, т.е. в свободное место дисков (незадействованное, и явно что lun не ограничивает) и пофиг сколько потоков и что они рандом, все пишется последовательно в свободное место. Попутно создается таблица соответствия &#8220;виртуальных&#8221; и &#8220;реальных&#8221; секторов. Как &#8220;свободное&#8221; место заканчивается, если под lun&#8217;ы было отведено не более половины места, значит то &#8220;физическое&#8221; место уже свободно и туда продолжается запись потоком и т.д. Вот если сделать рандом тест на объем равный физическому месту на диске, то после записи первого полного объема (назовем инициализацией) начнется настоящая рандом запись со всеми вытекающими&#8230; при этом даже линейная запись на wafl привратится в рандом. О ужас. Вообщем синтетику сделать, чтобы netapp был в попе видимо не сложно. Куда интересней, как в реальной жизни он поведет.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1154</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Mon, 21 Feb 2011 10:50:05 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1154</guid>
		<description>panvartan:
&gt; неужели это и есть факторы дающие такие разные результаты?
Ну отчего нет? Вполне возможно. У NetApp на самом деле очень эффктивная random write.
Сравнивать же по абсолютной величине разную по характеру нагрузку нельзя совершенно точно, это азбука нагрузочного тестирования.

&gt; 1,5 тб. в кэш есно не поместится
Все - не поместится, но может поместиться какая-то часть, а так как доступ - random, то есть вероятность, что этот random произойдет в пределах фрагмента в кэше. Таким образом, при random access, даже при dataset-е значительно больше кэша, кэш не простаивает без дела, а улучшает показатели производительности.</description>
		<content:encoded><![CDATA[<p>panvartan:<br />
> неужели это и есть факторы дающие такие разные результаты?<br />
Ну отчего нет? Вполне возможно. У NetApp на самом деле очень эффктивная random write.<br />
Сравнивать же по абсолютной величине разную по характеру нагрузку нельзя совершенно точно, это азбука нагрузочного тестирования.</p>
<p>> 1,5 тб. в кэш есно не поместится<br />
Все - не поместится, но может поместиться какая-то часть, а так как доступ - random, то есть вероятность, что этот random произойдет в пределах фрагмента в кэше. Таким образом, при random access, даже при dataset-е значительно больше кэша, кэш не простаивает без дела, а улучшает показатели производительности.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: panvartan</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1153</link>
		<dc:creator>panvartan</dc:creator>
		<pubDate>Mon, 21 Feb 2011 10:30:51 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1153</guid>
		<description>Гм, насколько я помню IOmeter , если не указано иное, заполняет тестовыми данными все доступное дисковое пространство, 1,5 тб. в кэш есно не поместится. За 10 дней со скоростью 47 мб/с действительно 36тб перепишется, но каким образом диск на 5400 переварит  486 IOPS записи, они телепатически на нем изменятся?  
Чуть ниже описывалась другой тест "протестированный FAS2020 был сконфигурирован с 16 LUN-ами по 8GB каждый, на общем томе FlexVol, лежащим на 24 дисках SAS/FC 15KRPM (12 SAS + 14 FC)... дразмер блока - 8KB, 70% random, read/write=40/60 ... При указанных условиях, система FAS2020 достигла показателей в 6000 IOPS" Это 240 IOPS на диск, что похоже на индивидуальную производительность диска. Да в этом тесте присутствует чтение, а в первом размер блока совпадает с блоком wafl, неужели это и есть факторы дающие такие разные результаты?</description>
		<content:encoded><![CDATA[<p>Гм, насколько я помню IOmeter , если не указано иное, заполняет тестовыми данными все доступное дисковое пространство, 1,5 тб. в кэш есно не поместится. За 10 дней со скоростью 47 мб/с действительно 36тб перепишется, но каким образом диск на 5400 переварит  486 IOPS записи, они телепатически на нем изменятся?<br />
Чуть ниже описывалась другой тест &#8220;протестированный FAS2020 был сконфигурирован с 16 LUN-ами по 8GB каждый, на общем томе FlexVol, лежащим на 24 дисках SAS/FC 15KRPM (12 SAS + 14 FC)&#8230; дразмер блока - 8KB, 70% random, read/write=40/60 &#8230; При указанных условиях, система FAS2020 достигла показателей в 6000 IOPS&#8221; Это 240 IOPS на диск, что похоже на индивидуальную производительность диска. Да в этом тесте присутствует чтение, а в первом размер блока совпадает с блоком wafl, неужели это и есть факторы дающие такие разные результаты?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1152</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Mon, 21 Feb 2011 09:53:19 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1152</guid>
		<description>panvartan:
Ну почему нет? На что кэш даден?</description>
		<content:encoded><![CDATA[<p>panvartan:<br />
Ну почему нет? На что кэш даден?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: panvartan</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1151</link>
		<dc:creator>panvartan</dc:creator>
		<pubDate>Mon, 21 Feb 2011 09:42:21 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1151</guid>
		<description>"Вы видите показатель производительности, равный 11248 IOPS при 4,2ms latency. 
Довольно неплохо для 24 дисков SATA."
Это 486 IOPS с диска Maxtor MaxLine II 5400RPM ? Что я не понимаю?</description>
		<content:encoded><![CDATA[<p>&#8220;Вы видите показатель производительности, равный 11248 IOPS при 4,2ms latency.<br />
Довольно неплохо для 24 дисков SATA.&#8221;<br />
Это 486 IOPS с диска Maxtor MaxLine II 5400RPM ? Что я не понимаю?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1149</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Mon, 21 Feb 2011 07:59:53 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1149</guid>
		<description>Allilya:

Если вы "перетестите по нормальному" я с удовольствием опубликую ваши результаты, пока же - публикую те данные, что есть.</description>
		<content:encoded><![CDATA[<p>Allilya:</p>
<p>Если вы &#8220;перетестите по нормальному&#8221; я с удовольствием опубликую ваши результаты, пока же - публикую те данные, что есть.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: Allilya</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1148</link>
		<dc:creator>Allilya</dc:creator>
		<pubDate>Mon, 21 Feb 2011 07:52:54 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1148</guid>
		<description>Это претензии к статье - меряли совсем непонятно что. Я бы такой позор либо удалил, либо перетестил по-нормальному.</description>
		<content:encoded><![CDATA[<p>Это претензии к статье - меряли совсем непонятно что. Я бы такой позор либо удалил, либо перетестил по-нормальному.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1141</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Sat, 19 Feb 2011 03:17:35 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1141</guid>
		<description>Allilya:
У вас, для новичка, какие-то немного смешные претении к NetApp. :)
"Корабль пойдет на дно..." - "Вах, баюс" ;)</description>
		<content:encoded><![CDATA[<p>Allilya:<br />
У вас, для новичка, какие-то немного смешные претении к NetApp. :)<br />
&#8220;Корабль пойдет на дно&#8230;&#8221; - &#8220;Вах, баюс&#8221; ;)</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: Allilya</title>
		<link>http://blog.aboutnetapp.ru/archives/820#comment-1139</link>
		<dc:creator>Allilya</dc:creator>
		<pubDate>Fri, 18 Feb 2011 23:13:22 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/archives/820#comment-1139</guid>
		<description>Ой, не sas, а fc конечно. Вообщем стыдно за hdd. В такие недешевые железки, как netapp, можно было и ssd ставить. FlexCache видимо как спасательный круг. Но помогает временно, при дальнейшей нагрузке корабль пойдет на дно, все.

P.S. У WAFL ествественно единственный существенный изъян - при фрагментации просядет линейное чтение до показателей рандом чтения в экстремальных случаях. Если конечно есть дикая и постоянная линейная запись в несколько потоков, то там тоже будет плохо без дефрагментации, хотя на "обычных" железках тоже не факт что будет хорошо. (вроде как характерно к видео-серверам, видимо на этот кусок рынка netapp никак не претендует) Собственно, чем тут внутренняя фрагментация СХД отличается от фрагментации hdd? Проблема одна и таже! Но это кончено при обычных hdd, при переходе на ssd все поменяется, хотя и wafl на ssd потеряет всякий смысл ибо ssd уже внутренне работает по аналогичной схеме.</description>
		<content:encoded><![CDATA[<p>Ой, не sas, а fc конечно. Вообщем стыдно за hdd. В такие недешевые железки, как netapp, можно было и ssd ставить. FlexCache видимо как спасательный круг. Но помогает временно, при дальнейшей нагрузке корабль пойдет на дно, все.</p>
<p>P.S. У WAFL ествественно единственный существенный изъян - при фрагментации просядет линейное чтение до показателей рандом чтения в экстремальных случаях. Если конечно есть дикая и постоянная линейная запись в несколько потоков, то там тоже будет плохо без дефрагментации, хотя на &#8220;обычных&#8221; железках тоже не факт что будет хорошо. (вроде как характерно к видео-серверам, видимо на этот кусок рынка netapp никак не претендует) Собственно, чем тут внутренняя фрагментация СХД отличается от фрагментации hdd? Проблема одна и таже! Но это кончено при обычных hdd, при переходе на ssd все поменяется, хотя и wafl на ssd потеряет всякий смысл ибо ssd уже внутренне работает по аналогичной схеме.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
