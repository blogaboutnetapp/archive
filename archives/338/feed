<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	>
<channel>
	<title>Комментарии к записи: Проблемы и решения Usable Space. Часть 3.</title>
	<atom:link href="http://blog.aboutnetapp.ru/archives/338/feed" rel="self" type="application/rss+xml" />
	<link>http://blog.aboutnetapp.ru/archives/338</link>
	<description>Системы хранения данных как предмет разговора</description>
	<pubDate>Wed, 07 Apr 2021 12:06:49 +0000</pubDate>
	<generator>http://wordpress.org/?v=2.6</generator>
		<item>
		<title>Автор: Алексей</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2712</link>
		<dc:creator>Алексей</dc:creator>
		<pubDate>Thu, 14 Jun 2012 13:22:09 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2712</guid>
		<description>Понятно. С проекцией на OSI и отдельные уровни - яснее.</description>
		<content:encoded><![CDATA[<p>Понятно. С проекцией на OSI и отдельные уровни - яснее.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2711</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Thu, 14 Jun 2012 13:17:41 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2711</guid>
		<description>Алексей:

Ну тут вот какая ситуация. Обычная файловая система, чем бы она ни была, находится на некоем уровне по отношению к дискам. Вот в отношении сетевой структуры это понятнее, потому что там есть формализованная модель ISO OSI, и оперируя ее делением можно показать, что "эта файловая система, она отсюа и досюда". К сожалени для дисковых структур такого пока нет.

Если вы найдете здесь перевод статьи Костадиса Руссоса, про то, как устроен WAFL, там может быть написано понятнее.
WAFL (как и ZFS) расположена "смещенной вниз" относительно обычной иерархии, привычного ее деления. То есть, если в случае обычной файловой системы, FS "живет" поверх дисков, над которыми находтся какой-то RAID, над которым какой-то volume manager, и вот там, над Volume manager уже файловая система, то в случае WAFL (и ZFS) она же сама по себе является и RAID, и Volume Manager, однако, при этом, она не реализует ряд задач "верхнего уровня", которые обычно умеет делать "файловая система", но не делает WAFL, предоставляя только инструментарий, примитивы для написания подобных функций.
Это, в числе прочего, позволило на базе WAFL реализовать и блочную семантику, для использования в SAN, просто потому что и файловая и блочная семантика не была встроена как таковая, а была надстроена по необходимости в Data ONTAP.

То есть WAFL это "файловая система", смещенная на два уровня иерархии вниз, если Level 1 считать физические диски, Level 2 - RAID, Level 3 - Volume Manager, и так далее. WAFL начинается от уровня 2, и продолжается до уровня, допустим, 5, в то время, как "обычная FS, начинается от уровня 4, и продолжается до уровня 7.

Таким образом в WAFL нет уроаня RAID как такового, отдельного от файловой системы, просто WAFL, живущая поверх физическх дисков непосредственно, формирует RAID-подобную избыточную структуру блоков, просто записывая данные в определенном порядке. У WAFL нет некоего отдельного уровня RAID, который можно по желанию включить или выключить, есть просто вот такая вот структура записи данных, которая реализует принципы RAID путем встроенных возможностей WAFL.
Также работает ZFS, и ее RAID-Z/Z2, возможно, вследствие ее открыторсти, будет проще найти детали реализации, которые, с определенным приближением, можно перенести на WAFL и разобраться "как это работает".</description>
		<content:encoded><![CDATA[<p>Алексей:</p>
<p>Ну тут вот какая ситуация. Обычная файловая система, чем бы она ни была, находится на некоем уровне по отношению к дискам. Вот в отношении сетевой структуры это понятнее, потому что там есть формализованная модель ISO OSI, и оперируя ее делением можно показать, что &#8220;эта файловая система, она отсюа и досюда&#8221;. К сожалени для дисковых структур такого пока нет.</p>
<p>Если вы найдете здесь перевод статьи Костадиса Руссоса, про то, как устроен WAFL, там может быть написано понятнее.<br />
WAFL (как и ZFS) расположена &#8220;смещенной вниз&#8221; относительно обычной иерархии, привычного ее деления. То есть, если в случае обычной файловой системы, FS &#8220;живет&#8221; поверх дисков, над которыми находтся какой-то RAID, над которым какой-то volume manager, и вот там, над Volume manager уже файловая система, то в случае WAFL (и ZFS) она же сама по себе является и RAID, и Volume Manager, однако, при этом, она не реализует ряд задач &#8220;верхнего уровня&#8221;, которые обычно умеет делать &#8220;файловая система&#8221;, но не делает WAFL, предоставляя только инструментарий, примитивы для написания подобных функций.<br />
Это, в числе прочего, позволило на базе WAFL реализовать и блочную семантику, для использования в SAN, просто потому что и файловая и блочная семантика не была встроена как таковая, а была надстроена по необходимости в Data ONTAP.</p>
<p>То есть WAFL это &#8220;файловая система&#8221;, смещенная на два уровня иерархии вниз, если Level 1 считать физические диски, Level 2 - RAID, Level 3 - Volume Manager, и так далее. WAFL начинается от уровня 2, и продолжается до уровня, допустим, 5, в то время, как &#8220;обычная FS, начинается от уровня 4, и продолжается до уровня 7.</p>
<p>Таким образом в WAFL нет уроаня RAID как такового, отдельного от файловой системы, просто WAFL, живущая поверх физическх дисков непосредственно, формирует RAID-подобную избыточную структуру блоков, просто записывая данные в определенном порядке. У WAFL нет некоего отдельного уровня RAID, который можно по желанию включить или выключить, есть просто вот такая вот структура записи данных, которая реализует принципы RAID путем встроенных возможностей WAFL.<br />
Также работает ZFS, и ее RAID-Z/Z2, возможно, вследствие ее открыторсти, будет проще найти детали реализации, которые, с определенным приближением, можно перенести на WAFL и разобраться &#8220;как это работает&#8221;.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: Алексей</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2710</link>
		<dc:creator>Алексей</dc:creator>
		<pubDate>Thu, 14 Jun 2012 12:50:34 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2710</guid>
		<description>Спасибо за документ. Теперь более понятно! Указанная статья - как best ptactice для архитекторов, весьма полезна. Мне нужно было нечто вроде этого: http://ru.wikipedia.org/wiki/Hot_Spare :-D

&#62;Строго говоря, в WAFL, на дисках NetApp, RAID-а, как такового, нет. Это в значительной мере абстракция, имеющая цель быть понятной “традиционным” стораджистам.
Не понял. Производитель придумал абстрактное понятие только для того, чтобы пользователям, подсевшим на "устаревающие" решения, было понятно? ??нтересно, а не правильнее ли было заявить - "RAID больше не нужен, а вот почему! ...". 
?? все-таки, от традиционного понятия "RAID" здесь много: дисковый массив есть? есть. избыточность ради отказоустойчивости есть? есть. диски parity есть? есть. hot spare - есть? есть. увеличение производительности за счет "размазывания" данных по дискам есть? есть.

вот что говорит вики:
"Дальнейшее развитие идеи RAID:
??дея RAID-массивов — в объединении дисков, каждый из которых рассматривается как набор секторов, и в результате драйвер файловой системы «видит» как бы единый диск и работает с ним, не обращая внимания на его внутреннюю структуру. Однако, можно добиться существенного повышения производительности и надёжности дисковой системы, если драйвер файловой системы будет «знать» о том, что работает не с одним диском, а с набором дисков.

Более того: при разрушении любого из дисков в составе RAID-0 вся информация в массиве окажется потерянной. Но если драйвер файловой системы разместил каждый файл на одном диске, и при этом правильно организована структура директорий, то при разрушении любого из дисков будут потеряны только файлы, находившиеся на этом диске; а файлы, целиком находящиеся на сохранившихся дисках, останутся доступными."

Я правильно понимаю, что RAID уровнем управляет WAFL? ?? он как раз таки знает о существовании дисков, распределяя блоки (не файлы) по массиву зная на каком диске какой блок?</description>
		<content:encoded><![CDATA[<p>Спасибо за документ. Теперь более понятно! Указанная статья - как best ptactice для архитекторов, весьма полезна. Мне нужно было нечто вроде этого: <a href="http://ru.wikipedia.org/wiki/Hot_Spare" rel="nofollow">http://ru.wikipedia.org/wiki/Hot_Spare</a> :-D</p>
<p>&gt;Строго говоря, в WAFL, на дисках NetApp, RAID-а, как такового, нет. Это в значительной мере абстракция, имеющая цель быть понятной “традиционным” стораджистам.<br />
Не понял. Производитель придумал абстрактное понятие только для того, чтобы пользователям, подсевшим на &#8220;устаревающие&#8221; решения, было понятно? ??нтересно, а не правильнее ли было заявить - &#8220;RAID больше не нужен, а вот почему! &#8230;&#8221;.<br />
?? все-таки, от традиционного понятия &#8220;RAID&#8221; здесь много: дисковый массив есть? есть. избыточность ради отказоустойчивости есть? есть. диски parity есть? есть. hot spare - есть? есть. увеличение производительности за счет &#8220;размазывания&#8221; данных по дискам есть? есть.</p>
<p>вот что говорит вики:<br />
&#8220;Дальнейшее развитие идеи RAID:<br />
??дея RAID-массивов — в объединении дисков, каждый из которых рассматривается как набор секторов, и в результате драйвер файловой системы «видит» как бы единый диск и работает с ним, не обращая внимания на его внутреннюю структуру. Однако, можно добиться существенного повышения производительности и надёжности дисковой системы, если драйвер файловой системы будет «знать» о том, что работает не с одним диском, а с набором дисков.</p>
<p>Более того: при разрушении любого из дисков в составе RAID-0 вся информация в массиве окажется потерянной. Но если драйвер файловой системы разместил каждый файл на одном диске, и при этом правильно организована структура директорий, то при разрушении любого из дисков будут потеряны только файлы, находившиеся на этом диске; а файлы, целиком находящиеся на сохранившихся дисках, останутся доступными.&#8221;</p>
<p>Я правильно понимаю, что RAID уровнем управляет WAFL? ?? он как раз таки знает о существовании дисков, распределяя блоки (не файлы) по массиву зная на каком диске какой блок?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2697</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Wed, 13 Jun 2012 13:33:03 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2697</guid>
		<description>bbk:

Ну почему сразу "потеряли"? Я не считаю, что диски, потраченные на обеспечение высокой доступности данных надо называть "потерянные".
Впрочем, это зависит от хранимых данных ;-D</description>
		<content:encoded><![CDATA[<p>bbk:</p>
<p>Ну почему сразу &#8220;потеряли&#8221;? Я не считаю, что диски, потраченные на обеспечение высокой доступности данных надо называть &#8220;потерянные&#8221;.<br />
Впрочем, это зависит от хранимых данных ;-D</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: bbk</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2696</link>
		<dc:creator>bbk</dc:creator>
		<pubDate>Wed, 13 Jun 2012 13:12:34 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2696</guid>
		<description>Я бы добавил, что количество хотсперов может ещё диктоваться "особеннстью" работы CF и использования &lt;a href="http://blog.aboutnetapp.ru/archives/1090" rel="nofollow"&gt;mailbox дисков&lt;/a&gt;.

Кроме того нужны отдельные Hot Spare на каждый тип дисков.
К примеру: у нас 24 SAS и 24 SATA, каждому контроллеру отдаём половину от того и другого типа дисков. Получаем по 12 дисков SAS и 12 SATA на контроллер. Так как каждый контроллер владеет своим набором дисков (общих быть не может, даже Hot Spare): ??з каждой дюжины заберём по два на парити и по два на Hot Spare. ??того потеряли 4-ре SAS и 4-ре SATA диска на HA системе.</description>
		<content:encoded><![CDATA[<p>Я бы добавил, что количество хотсперов может ещё диктоваться &#8220;особеннстью&#8221; работы CF и использования <a href="http://blog.aboutnetapp.ru/archives/1090" rel="nofollow">mailbox дисков</a>.</p>
<p>Кроме того нужны отдельные Hot Spare на каждый тип дисков.<br />
К примеру: у нас 24 SAS и 24 SATA, каждому контроллеру отдаём половину от того и другого типа дисков. Получаем по 12 дисков SAS и 12 SATA на контроллер. Так как каждый контроллер владеет своим набором дисков (общих быть не может, даже Hot Spare): ??з каждой дюжины заберём по два на парити и по два на Hot Spare. ??того потеряли 4-ре SAS и 4-ре SATA диска на HA системе.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2693</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Wed, 13 Jun 2012 09:13:21 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2693</guid>
		<description>Алексей:

Официальный источник - NetApp Resiliency Guide. Я делал его перевод в библиотеку Netwell.
http://netwell.ru/docs/netapp/tr-3437_rus_storage_subsystems_resiliency_guide.pdf

Если же "к черту подробности", то правила простые:

1. Hotspare назначается на контроллер (два контроллера - значит минимум 2 hotspare в системе суммарно, по одному на контроллер). Эксплуатация систем без hotspares не поддерживается производителем.

2. Количество рекомендованных hotspares выбирается исходя из требований к системе хранения, конкретнее к надежности хранения хранимых на ней данных. Но общее эмпирическое правило: "2 spares на первых 84 диска, на каждый контроллер, и по 1 диску на каждые последующие 84 диска". Это, конечно, не распространяется на системы типа 2xx0, где общее число дисков обычно значительно менее 84.
В общем, если лень читать весь TR3437, то читайте только главу 5.4

3. Все диски, которые пока не назначены в aggregate или traditional volume, являются для системы hot spares.

&gt; Я думал, что hotspare рекомендуется делать в каждом RAID.

Строго говоря, в WAFL, на дисках NetApp, RAID-а, как такового, нет. Это в значительной мере абстракция, имеющая цель быть понятной "традиционным" стораджистам.
Для WAFL "RAID" - это порядок и последовательность записи блоков данных на имеющиеся в наличии диски.</description>
		<content:encoded><![CDATA[<p>Алексей:</p>
<p>Официальный источник - NetApp Resiliency Guide. Я делал его перевод в библиотеку Netwell.<br />
<a href="http://netwell.ru/docs/netapp/tr-3437_rus_storage_subsystems_resiliency_guide.pdf" rel="nofollow">http://netwell.ru/docs/netapp/tr-3437_rus_storage_subsystems_resiliency_guide.pdf</a></p>
<p>Если же &#8220;к черту подробности&#8221;, то правила простые:</p>
<p>1. Hotspare назначается на контроллер (два контроллера - значит минимум 2 hotspare в системе суммарно, по одному на контроллер). Эксплуатация систем без hotspares не поддерживается производителем.</p>
<p>2. Количество рекомендованных hotspares выбирается исходя из требований к системе хранения, конкретнее к надежности хранения хранимых на ней данных. Но общее эмпирическое правило: &#8220;2 spares на первых 84 диска, на каждый контроллер, и по 1 диску на каждые последующие 84 диска&#8221;. Это, конечно, не распространяется на системы типа 2xx0, где общее число дисков обычно значительно менее 84.<br />
В общем, если лень читать весь TR3437, то читайте только главу 5.4</p>
<p>3. Все диски, которые пока не назначены в aggregate или traditional volume, являются для системы hot spares.</p>
<p>> Я думал, что hotspare рекомендуется делать в каждом RAID.</p>
<p>Строго говоря, в WAFL, на дисках NetApp, RAID-а, как такового, нет. Это в значительной мере абстракция, имеющая цель быть понятной &#8220;традиционным&#8221; стораджистам.<br />
Для WAFL &#8220;RAID&#8221; - это порядок и последовательность записи блоков данных на имеющиеся в наличии диски.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: Алексей</title>
		<link>http://blog.aboutnetapp.ru/archives/338#comment-2692</link>
		<dc:creator>Алексей</dc:creator>
		<pubDate>Wed, 13 Jun 2012 08:45:51 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=338#comment-2692</guid>
		<description>Привет!
Подскажите плз. ресурс, где можно доходчиво и без глубоких подробностей прочитать о назначении hotspare дисков в СХД? 
Не ошибка, что кол-во hotspare зависит от кол-ва контроллеров? Я думал, что hotspare рекомендуется делать в каждом RAID.</description>
		<content:encoded><![CDATA[<p>Привет!<br />
Подскажите плз. ресурс, где можно доходчиво и без глубоких подробностей прочитать о назначении hotspare дисков в СХД?<br />
Не ошибка, что кол-во hotspare зависит от кол-ва контроллеров? Я думал, что hotspare рекомендуется делать в каждом RAID.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
