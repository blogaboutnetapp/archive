<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	>
<channel>
	<title>Комментарии к записи: Лучше Чем Настоящий FibreChannel - Дедупликация</title>
	<atom:link href="http://blog.aboutnetapp.ru/archives/312/feed" rel="self" type="application/rss+xml" />
	<link>http://blog.aboutnetapp.ru/archives/312</link>
	<description>Системы хранения данных как предмет разговора</description>
	<pubDate>Wed, 07 Apr 2021 12:07:26 +0000</pubDate>
	<generator>http://wordpress.org/?v=2.6</generator>
		<item>
		<title>Автор: bbk</title>
		<link>http://blog.aboutnetapp.ru/archives/312#comment-2706</link>
		<dc:creator>bbk</dc:creator>
		<pubDate>Thu, 14 Jun 2012 06:29:49 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=312#comment-2706</guid>
		<description>bbk&#62; Мне кажется, что вы здесь подменили понятие случайных данных собранных в страйп на блочную фрагментированность от процесса дедупликации.

Спрайтом я называю данные собранные одним большим куском в NVRAM оптимизированным для записи на диски.
Одно дело фрагментированность вызванная процессом дедупликации.
Другое дело фрагментированность данных внутри страйпа.

Другими словами я усомнился в том, что данные внутри страйпа 100% random.
Как работает алгоритм собирания данных в страйп?</description>
		<content:encoded><![CDATA[<p>bbk&gt; Мне кажется, что вы здесь подменили понятие случайных данных собранных в страйп на блочную фрагментированность от процесса дедупликации.</p>
<p>Спрайтом я называю данные собранные одним большим куском в NVRAM оптимизированным для записи на диски.<br />
Одно дело фрагментированность вызванная процессом дедупликации.<br />
Другое дело фрагментированность данных внутри страйпа.</p>
<p>Другими словами я усомнился в том, что данные внутри страйпа 100% random.<br />
Как работает алгоритм собирания данных в страйп?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: romx</title>
		<link>http://blog.aboutnetapp.ru/archives/312#comment-2698</link>
		<dc:creator>romx</dc:creator>
		<pubDate>Wed, 13 Jun 2012 14:02:24 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=312#comment-2698</guid>
		<description>bkk:

&gt; Мне кажется, что вы здесь подменили понятие &lt;b&gt;случайных данных собранных в страйп&lt;/b&gt; &lt;i&gt;на&lt;/i&gt; &lt;b&gt;блочную фрагментированность от процесса дедупликации&lt;/b&gt;.

Несколько раз прочел, но смысла так и не уловил. Перформулируйте, и пропробуйте еще раз.

Я бы хотел еще раз, специально, обратит ваще внимание, что влияние фрагментации на 100% random workload по меньшей мере не доказано.
С точки зрения теории и логики, разницы между рандомным чтением рандомно расположенных данных и рандомным чтением секвентально расположенных ланных нет никакой. В обоих случаях это чтение 100% random. рандом на рандом не дает "рандом в квадрате", он по прежнему остается 100% рандомным.

Секвентальное же чтение это довольно специфические задачи, типа традиционного бэкапа. На этих задачах фрагментация действительно будет ухудшать показатели sequental read, но в случае NetApp задачи бэкапа обычно решаются иными путями, не требующими лить секвентальный дамп с дисков.</description>
		<content:encoded><![CDATA[<p>bkk:</p>
<p>> Мне кажется, что вы здесь подменили понятие <b>случайных данных собранных в страйп</b> <i>на</i> <b>блочную фрагментированность от процесса дедупликации</b>.</p>
<p>Несколько раз прочел, но смысла так и не уловил. Перформулируйте, и пропробуйте еще раз.</p>
<p>Я бы хотел еще раз, специально, обратит ваще внимание, что влияние фрагментации на 100% random workload по меньшей мере не доказано.<br />
С точки зрения теории и логики, разницы между рандомным чтением рандомно расположенных данных и рандомным чтением секвентально расположенных ланных нет никакой. В обоих случаях это чтение 100% random. рандом на рандом не дает &#8220;рандом в квадрате&#8221;, он по прежнему остается 100% рандомным.</p>
<p>Секвентальное же чтение это довольно специфические задачи, типа традиционного бэкапа. На этих задачах фрагментация действительно будет ухудшать показатели sequental read, но в случае NetApp задачи бэкапа обычно решаются иными путями, не требующими лить секвентальный дамп с дисков.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Автор: bbk</title>
		<link>http://blog.aboutnetapp.ru/archives/312#comment-2695</link>
		<dc:creator>bbk</dc:creator>
		<pubDate>Wed, 13 Jun 2012 12:56:49 +0000</pubDate>
		<guid isPermaLink="false">http://blog.aboutnetapp.ru/?p=312#comment-2695</guid>
		<description>Вопрос о фрагментации от процесса дедупликации и её влияния на производительность системы, поднят очень интересный.
Но ответ не достаточно описателен.

??сходя из поста можно сказать, что проблема решается исключительно кешем на чтение и реалокацией (которая по умолчанию выключена).

Мне кажется, что вы здесь подменили понятие &lt;b&gt;случайных данных собранных в страйп&lt;/b&gt; &lt;i&gt;на&lt;/i&gt; &lt;b&gt;блочную фрагментированность от процесса дедупликации&lt;/b&gt;. ?? тут встаёт вопрос есть ли разница между тем и другим?

Вопрос сводится к тому, как работает алгоритм сбора "случайных" данных в страйп. Другими словами: насколько дынные внутри страйпа фрагментированны и является ли длинна такого фрагмента, в страйпе, постоянной, если там не 100%-й рандум?

Если алгоритм совсем тупой, то скорее всего оба понятия одно и тоже. Похоже вы к этому и клоните: производительность не падает от случайного чтения случайно разбросанных данных.

Но если алгоритм умный и понимает, что случайные блоки относятся к одной логической цепочке, то не такие уж и фрагментированные данные получаются в нашем страйпе, а следовательно выше изложенные понятия не следует мешать в кучу. Продолжая эту логику, я бы заключил, что дедупликация всё-таки сильно фрагментирует данные, в то время как они расположены не случайно, а более или менее последовательно. Соответственно должна быть деградация производительности от фрагментации вызванной дедупликацией.

Как известно падения производительности от дедупликации всё-таки нет, но мы так до конца и не понимаем почему. Было бы неплохо закрыть эту дыру.</description>
		<content:encoded><![CDATA[<p>Вопрос о фрагментации от процесса дедупликации и её влияния на производительность системы, поднят очень интересный.<br />
Но ответ не достаточно описателен.</p>
<p>??сходя из поста можно сказать, что проблема решается исключительно кешем на чтение и реалокацией (которая по умолчанию выключена).</p>
<p>Мне кажется, что вы здесь подменили понятие <b>случайных данных собранных в страйп</b> <i>на</i> <b>блочную фрагментированность от процесса дедупликации</b>. ?? тут встаёт вопрос есть ли разница между тем и другим?</p>
<p>Вопрос сводится к тому, как работает алгоритм сбора &#8220;случайных&#8221; данных в страйп. Другими словами: насколько дынные внутри страйпа фрагментированны и является ли длинна такого фрагмента, в страйпе, постоянной, если там не 100%-й рандум?</p>
<p>Если алгоритм совсем тупой, то скорее всего оба понятия одно и тоже. Похоже вы к этому и клоните: производительность не падает от случайного чтения случайно разбросанных данных.</p>
<p>Но если алгоритм умный и понимает, что случайные блоки относятся к одной логической цепочке, то не такие уж и фрагментированные данные получаются в нашем страйпе, а следовательно выше изложенные понятия не следует мешать в кучу. Продолжая эту логику, я бы заключил, что дедупликация всё-таки сильно фрагментирует данные, в то время как они расположены не случайно, а более или менее последовательно. Соответственно должна быть деградация производительности от фрагментации вызванной дедупликацией.</p>
<p>Как известно падения производительности от дедупликации всё-таки нет, но мы так до конца и не понимаем почему. Было бы неплохо закрыть эту дыру.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
