<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="ru-RU">

<head profile="http://gmpg.org/xfn/11">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<title>about NetApp   &raquo; cluster-mode</title>

<link rel="stylesheet" href="../../../../wp-content/themes/fluid-blue/style.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../../../wp-content/themes/fluid-blue/print.css" type="text/css" media="print" />
<link rel="alternate" type="application/rss+xml" title="about NetApp RSS Feed" href="../../../../feed" />
<link rel="pingback" href="../../../../xmlrpc.php.html" />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../../../xmlrpc.php%3Frsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../../../wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 2.6" />

</head>

<body>
<div id="page">
<div id="header">
	<div id="headertitle">
		<h1><a href="../../../../index.html" title="about NetApp: Системы хранения данных как предмет разговора">about NetApp</a></h1>
		<p>Системы хранения данных как предмет разговора</p>
	</div> 
	<!-- Search box (If you prefer having search form as a sidebar widget, remove this block) -->
	<div class="search">
		<form method="get" id="searchform" action="../../../../index.html">
<input type="text" size="20" name="s" id="s" value="Поиск..."  onblur="if(this.value=='') this.value='Поиск...';" onfocus="if(this.value=='Поиск...') this.value='';"/>
</form>
	</div> 
	<!-- Search ends here-->
		
</div>

<div id="navbar">
<ul id="nav">
	<li><a href="../../../../index.html">Home</a></li>
	<li class="page_item page-item-153"><a href="../../../../about/trackback.html" title="about">about</a></li>
<li class="page_item page-item-215"><a href="../../../../distributory-v-rossii/trackback.html" title="Дистрибуторы в России">Дистрибуторы в России</a></li>
<li class="page_item page-item-1327"><a href="../../../../disti-ua/trackback.html" title="Дистрибуторы в Украине">Дистрибуторы в Украине</a></li>
</ul>
</div>
<div id="wrapper">

	<div id="content">

	
			<p>Posts tagged &#8216;cluster-mode&#8217;</p>

	 		
		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"><a href="../index.html">Next Entries &raquo;</a></div>
		</div>

						
			<div class="post" id="post-1174">
				<h2 class="posttitle"><a href="../../../1174/trackback.html" rel="bookmark" title="Permanent Link to Еще о тестировании Cluster-mode в SPC-1">Еще о тестировании Cluster-mode в SPC-1</a></h2>
				<div class="postmetadata">27 Июнь 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Я не первый раз рубликую тут переводы постов инженера NetApp – Dimitris Krekoukias, ведущего автономный, и крайне интересный блог <a href="http://recoverymonkey.org/">http://recoverymonkey.org/</a> (другие мои переводы его постов вы можете найти в рубрике “<a href="../../../category/translations/index.html">переводы</a>”)</p>
<p>После долгого молчания, Dimitris опубликовал пост, вызванный публикацией отличных результатов кластера FAS6240 в Data ONTAP 8.1.1 Cluster-mode в бенчмарке блочного (FC) доступа – SPC-1, о котором я уже написал в понедельник. Однако вопросу <em>почему</em> он так хорош, и <em>насколько именно</em> он хорош – посвящен сегодняшний перевод.</p>
<h2>NetApp опубликовал великолепные результаты тестирования Cluster-Mode в бенчмарке SPC-1</h2>
<p>Опубликовано <a href="http://recoverymonkey.org/2012/06/20/netapp-posts-great-cluster-mode-spc-1-result/">June 20, 2012</a></p>
<p>Мы тут в NetApp были довольно сильно заняты… заняты совершенствованием единственной в отрасли масштабируемой платформы хранения с универсальным доступом к данным, даже не считая множества разных других имеющихся в ней полезных штук.</p>
<p>Мы недавно выпустили ONTAP 8.1, которая, в Cluster-Mode, позволяет создать 24-узловой кластер (каждый узел которого может иметь до 8TB кэша) для задач NAS, и 4-узловой кластер для блочного доступа (FC и iSCSI).</p>
<p>А с выпуском ONTAP 8.1.1 (выпущенного 14 июня), мы увеличили лимит узлов для блочного доступа до 6, плюс добавили ряд дополнительных оптимизаций и возможностей. Между прочим, число узлов в кластере это пока только условный лимит официальной поддержки, это не жестко заданное ограничение.</p>
<p>После публикации нашего <a href="http://bit.ly/K2FBz1">рекордного результата в бенчмарке NFS</a>, люди спрашивали, как обстоит дело с производительностью блочного ввода-вывода в ONTAP Cluster-Mode, поэтому мы провели тестирование и опубликовали результаты бенчмарка SPC-1, используя часть той же системы, что уже была протестирована на SPEC sfs2008 NFS.</p>
<p>Для тех кто до сих пор думает, что NetApp не подходит для блочного доступа (это типичный FUD наших конкурентов): <strong>Это, на сегодня, лучший результат SPC-1 среди всех дисковых систем хранения, из расчета на уровень latency при достигнутом уровне IOPS</strong> (то есть возможно получить даже более высокие показатели IOPS на бОльших лимитах по latency, как я покажу далее в этом посте).</p>
<p>Вот ссылка на <a href="http://bit.ly/Kj3kvP">результаты</a> и еще одна <a href="http://www.storageperformance.org/results/benchmark_results_spc1#a00115">ссылка</a>, на полную версию со всей доступной информацией.</p>
<p>В этом блоге я уже <a href="http://bit.ly/hs4GMt">говорил</a> о том, что представляет собой бенчмарк SPC-1 . Вкратце: Бенчмарк SPC-1 это общепринятый в индустрии, аудируемый, бенчмарк блочного доступа к системе хранения (по Fiber Channel) который проводит стресс-тестирование дисковой подсистемы большим объемом записей, перезаписей, локальных &quot;хотспотов&quot; и смешанной произвольно/последовательной, чтение-после-записи, запись-после-чтения нагрузкой. Около 60% рабочей нагрузки это операции записи. Размеры используемых в бенчмарке операций ввода-вывода различны, от маленьких до больших (таким образом IOPS в бенчмарке SPC-1 не идентичны и не могут быть сравнены напрямую с классическим тестом IOPS в full random блоками 4KB).</p>
<p>Если сторадж успешно работает на нагрузке SPC-1,, он, обычно, также крайне производительно работает на сложной, чувствительной к показателям latency, динамично изменяющейся нагрузке типа баз данных, в особенности OLTP. Полная спецификация для смертельно любопытных может быть найдена <a href="http://bit.ly/Kj8Iz7">здесь</a>.</p>
<p>Трюк с бенчмарками обычно состоит в интерпретации результатов. Сама по себе величина достигнутых IOPS, хотя и полезна, но не показывает всей картины, и того, как данный результат соотносится с реальной жзнью и реальными приложениями. Мы попытаемся помочь расшифровать результаты в этом посте.</p>
<p>Перед тем, как мы перейдем к анализу и сравнению результатов, несколько замечаний для <a href="http://www.youtube.com/watch?v=3MaJy7LH5js">неверующих</a>:</p>
<ol>
<li>В тестах NetApp не используется диски &quot;с коротких ходом&quot; (short-stroking), так часто любимые многими вендорами, проводящими тестирование, при котором используется только внешняя, наиболее быстродействующая часть диска, где сочетается максимальная линейная скорость и малый разбег механики коромысла жесткого диска, на чем можно показать наилучшие результаты. Вместо этого мы используем настройку параметров системы , чтобы использовать всю поверхность дисков, и не зависеть от того, насколько заполнены данными диски. Смотрите полный отчет <a href="http://bit.ly/Kj5lrO">здесь</a>, страница 61. Для любителей распространять FUD: это эффективно &quot;старит&quot; состояние WAFL, приближая его к реальному состоянию реально эксплуатируемой системы. Мы также не используем оптимизацию размещения блоков путем их реаллокации. </li>
<li>Падения производительности в ходе продолжительного тестирования не наблюдалось. </li>
<li>Средняя величина latency (“All ASUs” в результатах) была плоской и оставалась ниже уровня 5ms на протяжении нескольких итераций теста, включая sustainability test в течение 10 часов (страница 28 полного отчета). </li>
<li>Не использовался дополнительный кэш, кроме того, который поставляется в базовой поставке FAS6240 (Контроллеры 6240 поставляются с Flash Cache емкостью 512GB, при максимальной возможной емкости данной модели 3TB на ноду (контроллер), то есть для работы с большими нагрузками есть еще значительный запас). </li>
<li>Это не &quot;звездолет&quot;, построенный исключительно для завовевания победы и установления рекорда в бенчмарке. Мы использовали сравнительно немного дисков, в сравнении с конфигурациями других вендоров, и это не самая быстрая наша модель контроллера (еще есть 6280). </li>
</ol>
<h3>Анализ</h3>
<p>Когда мы смотрим на результаты бенчмарка, следует сфокусироваться на следующих моментах:</p>
<ol>
<li>Высокий уровень установившейся производительности в IOPS (нестабильность показателей показывает на наличие проблем). </li>
<li>IOPS/диск (это показатель эффективности – 500 IOPS/drive это вдвое лучше и эффективнее, чем 250 IOPS/drive, что, как следствие, означает меньше необходимых дисков в системе, снижает ее стоимость, уменьшает физический занимаемые в датацентре объем, и так далее.) </li>
<li>Стабильно низкая latency (пики показывают наличие проблем). </li>
<li>IOPS связан и зависит от latency (Получили ли вы высокие показатели IOPS вместе с высокой latency на максимуме? Это практически используемо?) </li>
<li>Какой тип RAID использовался (RAID6? RAID10? RAID6 обеспечивает значительно лучшую защиту данных и лучшие результаты эффективности использования дискового пространства, чем зеркалирование, что ведет к снижению стоимость даже более надежного хранилища данных). </li>
<li>Какие диски использовались? Хотите ли вы покупать такие диски? </li>
<li>??спользовался ли autotiering? Если нет, то почему нет? Разве он не помог бы в такой сложной ситуации? </li>
<li>Какое оборудование потребовалось, чтобы получить стабильную производительность (сколько дисков и контроллеров потребовалось для построения системы? Означает ли это более сложную и дорогую систему? Как это все будет управляться?) </li>
<li>Цена (некоторые вендоры указывают цену уже с учетом дисконта, в то время как другие публикуют цену в list price, так что будьте тут внимательнее). </li>
<li>Цена/IOPS (наиболее полезная метрика – но следует сравнивать цену list price с list price). </li>
</ol>
<p>SPC-1 это бенчмарк НЕ для измерения максимума потока данных; для измерения чистого GB/s смотрите другие бенчмарки. Большинство систем не дает больше 4GB/s в этом бенчмарке, так как много операций в нем рандомные (и 4GB/s это довольно много для рандомного ввода-вывода).</p>
<h3>Сравнение систем</h3>
<p>В этой части мы сравним дисковые системы хранения. Предсказуемо &quot;чистые SSD&quot; (или RAM) системы хранения имеют, конечно, очень высокие показатели производительности, и могут подойти, если ваша задача - обеспечивать работу с небольшим объемом данных очень быстро.</p>
<p>Но мы сосредоточимся на задачах высоконадежных систем общего применения, которые обеспечивают одновременно и высокую производительность, и низкую latency, и большую емкость, за разумную цену, а также, одновременно, большое количество функциональных фич(снэпшоты, репликация, кэширование в flash (megacaching), thin provisioning, дедупликация, компрессия, многопротокольность, включая NAS, и так далее). Опа – оказывается никто из конкурентов не может сделать сразу все что умеет делать NetApp.</p>
<p>Ниже приведен список систем и ссылки на их полные отчеты тестирования SPC-1, где вы сможете найти всю необходимую информацию. Все эти системы имеют высокие результаты и относительно плоскую кривую latency.</p>
<ul>
<li><a href="http://bit.ly/Kj5lrO">NetApp 6240</a> </li>
<li><a href="http://bit.ly/NUThnK">IBM SVC with V7000</a> </li>
<li><a href="http://bit.ly/NUTDLb">IBM SVC with DS8700</a> </li>
<li><a href="http://bit.ly/NUTuHq">HDS VSP</a> </li>
<li><a href="http://bit.ly/NUTerZ">HP 3Par V800</a> </li>
<li><a href="http://bit.ly/NUTqrs">Huawei Symantec S8100</a> </li>
</ul>
<p>Также есть несколько других дисковых систем хранения, со значительными результатами по IOPS, но если мы посмотрим на их результаты sustained latency (“Sustainability – Average Response Time (ms) Distribution Data” в любом из полных отчетов) мы увидим, что общие показатели latency чересчур высоки и наблюдается значительная неравномерность, в особенности в начальной фазе, с пиками до 30ms (что крайне много), поэтому мы не взяли их в расчет.</p>
<p>Вот краткий перечень систем и их параметров, отсортированных в соответствии с latency. Кроме этого показана и их стоимость в ценах list price (это можно найти в полном отчете о тестировании) плюс стоимость операции $/IOPS, посчитанная исходя из list price (многие вендоры приводят в отчетах цену с уже введенной скидкой, чтобы цена выглядела пониже):</p>
<p>&#160;</p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/---Cluster-mode--SPC-1_EDD7/image.png" width="954" height="181" /></p>
<h3>…но ведь тут показано, что некоторые системы быстрее NetApp… Как так?</h3>
<p>Это зависит от того, насколько важен для вас показатель latency и его низкая величина (и от того, принимаете ли вы в расчет используемый тип RAID). Для подавляющего большинства нагрузок типа баз данных, низкая latency операций ввода-вывода гораздо предпочтительнее высоких показателей latency.</p>
<p>Вот как это увидеть:</p>
<ol>
<li>Выберите один из приведенных выше линков на полные отчеты Допустим это будет 3Par, так как он показывает одновременно и высокие показатели производительности, и высокие значения latency. </li>
<li>Найдем в отчете главу под названием &quot;Response Time – Throughput Curve&quot;. Например это страница 13 в <a href="http://bit.ly/NUTerZ">отчете по системе 3Par</a>. </li>
<li>Проследим, как latency резко растет при повышении загрузки системы. </li>
</ol>
<p>Например посмотрим на кривую 3Par:</p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/---Cluster-mode--SPC-1_EDD7/image_3.png" width="600" height="408" /></p>
<p>Заметьте то, как latency резко растет после некоей точки.</p>
<p>Теперь сравним с <a href="http://bit.ly/Kj5lrO">результатом NetApp</a> (страница 13):</p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/---Cluster-mode--SPC-1_EDD7/image_4.png" width="600" height="434" /></p>
<p>Отметьте, что результат NetApp не просто имеет хорошие показатели latency, но, что еще более важно, <em>latency остается хорошей и растет исключительно медленно по мере увеличения нагрузки на систему.</em></p>
<p>Вот почему колонка“SPC-1 IOPS around 3ms” была добавлена в таблицу. Фактически это ответ на вопрос <strong>что бы было, если бы уровень latency был в тесте одинаков для всех протестированных систем?</strong></p>
<p>Когда вы примете эту позицию, вы увидите, что система 3Par фактически медленнее, чем NetApp, если сравнить их на одинаково низком желаемом уровне latency.</p>
<p>Вы можете взять точные показатели latency из графика на странице 13, у NetApp таблица выглядит так (озаглавлено &quot;Response Time – Throughput Data&quot;):</p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/---Cluster-mode--SPC-1_EDD7/image_5.png" width="600" height="144" /></p>
<p>Действительно, при сравнении результатов мы видим, что только IBM SVC (с кучей стораджей V7000 за ним) оказывается быстрее NetApp при столь же хороших показателях latency. Что плавно подводит нас к следующей главе…</p>
<p>Сколько железа обеспечивает такую производительность?</p>
<p>Почти любая инженерная задача может быть решена, если дать приложению достаточное количество необходимого оборудования. <a href="http://bit.ly/NUThnK">Результат IBM</a> это как раз хороший пример того, как можно получить хороший результат собрав вместе большую кучу дорогостоящего железа:</p>
<ul>
<li>8 SVC контроллеров (virtualization engines) плюс… </li>
<li>…16 отдельных систем V7000… </li>
<li>…каждая состоящая из еще 2 контроллеров SVC и 2 контроллеров RAID </li>
<li>1920 дисков 146GB 15K RPM (не так-то просто такие купить нынче, не так ли?) </li>
<li>??того 40 контроллеров SVC (8 больших и 32 поменьше), 32 RAID-контроллера, и все это битком наполнено дисками. </li>
</ul>
<p>Даже отставив в сторону вопрос того, как это все управляется, сколько это потребляет электричества и как размещается, понятно, что это довольно большая система. Я даже не пытался посчитать, сколько тут процессоров и ядер работают параллельно, уверен, их много.</p>
<p>Сравним эту кухню с вариантом <a href="http://bit.ly/Kj5lrO">конфигурации NetApp</a>:</p>
<ul>
<li>6 контроллеров в одном кластере </li>
<li>432 диска 450GB 15K RPM (самый распространенный и массовый наш диск по состоянию на июнь 2012). </li>
</ul>
<h3>Вопросы (с удовольствие увижу ответы на них от других вендоров):</h3>
<ol>
<li>Что произойдет при использовании RAID6 у других вендоров? NetApp всегда тестирует системы с использованием своей версии RAID6 (RAID-DP). RAID6 значительно надежнее, чем зеркалирование, особенно в больших пулах (не говоря уже о более эффективном использовании пространства дисков). Большинство клиентов не хотят покупать большую систему в конфигурации <em>только-RAID10</em>… (пользователи - задавайте вопросы вашим вендорам. Тут нет никакого волшебства – ручаюсь, у них есть внутренние результаты для RAID6, попросите показать их вам). </li>
<li>Autotiering это одна из самых раскрученных сегодня фич, с признаками того, что это достижение, превосходящее изобретение пенициллина, или даже колеса, а может даже и огня… Однако никто из дисковых массивов не рассматривает использование SSD для autotiering (IBM опубликовала однажды результат – <a href="http://bit.ly/NezCt4">не впечатляет</a>, делайте выводы). Это при том, что бенчмарк, по своей спецификации активно создающий &quot;горячие точки&quot; (hotspots) нагрузки, должен бы быть здесь идеальным кандидатом для демонстрации эффективности… </li>
<li>Почему EMC и Dell не желают публиковать результаты SPC-1? (Они оба, кстати, члены SPC, Storage Performance Council). Только два этих вендора, из крупных игроков на рынке, кто еще не опубликовали свои результаты. EMC ранее говорила, что SPC-1 это нереалистичный тест – ну, типа <em>только ваше приложение с вашими данными на вашем сторадже может показать по-настоящему реальные результаты</em>. Это так, однако SPC-1 это общепринятый индустрией стандартный бенчмарк для блочного доступа произвольного характера, и отличная &quot;лакмусовая бумажка&quot;. </li>
<li>Для системы, которая регулярно позиционируется для нагрузки Tier-1, IBM XIV, результаты бенчмарков, увы, отсутствуют также, даже для самой новой ее Gen3. Неужели IBM стесняется показать свои результаты SPC-1 для этой системы? </li>
<li>Наконец – некоторые наши конкуренты продолжают утверждать, что NetApp, дескать, это &quot;не настоящий SAN&quot;, что это, якобы &quot;эмуляция SAN&quot;, и так далее. Что бы это все ни значило на самом деле – может быть подход NetApp, с такой &quot;эмуляцией&quot; оказывается, по факту, лучше?… Максимальная <em>write latency</em> в этом тесте составила 1.91ms для в основном записываемой нагрузки! </li>
</ol>
<h3>??тоговые мысли</h3>
<p>В накануне опубликованном результате бенчмарка SPC-1, NetApp показала вновь, что Data ONTAP в Cluster-Mode это высокопроизводительная и масштабируемая система, одинаково подходящая как для SAN, так и для NAS задач. Суммируя все вышесказанное, можно сказать, что ONTAP Cluster-Mode:</p>
<ul>
<li>Позволяет строить высокопроизводительные и динамически-масштабируемые кластеры хранения для FC, iSCSI, NFS и CIFS. </li>
<li>Демонстрирует низкую latency при высокой производительности. </li>
<li>Предлагает исключительно хорошее соотношение price/performance. </li>
<li>Позволяет доступ к данным одной ноды с любых других нод. </li>
<li>Перемещает данные между нодами, не прерывая работы с ними (включая CIFS, что ранее не было практически невозможно). </li>
<li>Поддерживает традиционные для NetApp возможности (оптимизацию процессов записи, взаимодействие с приложениями, снэпшоты, дедупликацию, компрессию, репликацию, thin provisioning, и кэширование во flash (megacaching). </li>
<li>Может работать на в точности тех же самых контроллерах FAS, что и в 7-mode, что защищает инвестиции. </li>
<li>Может виртуализовывать системы хранения, расположенные за ними. </li>
</ul>
<p>??сточник &lt;<a href="http://recoverymonkey.org/2012/06/20/netapp-posts-great-cluster-mode-spc-1-result/">http://recoverymonkey.org/2012/06/20/netapp-posts-great-cluster-mode-spc-1-result/</a>&gt; </p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="../../811.html" rel="tag">8.1.1</a>, <a href="../../benchmark/index.html" rel="tag">benchmark</a>, <a href="../index.html" rel="tag">cluster-mode</a>, <a href="../../iops.html" rel="tag">iops</a>, <a href="../../netapp/index.html" rel="tag">netapp</a>, <a href="../../performance/index.html" rel="tag">performance</a>, <a href="../../recoverymonkey.html" rel="tag">recoverymonkey</a>, <a href="../../spc-1.html" rel="tag">spc-1</a>, <a href="../../testing.html" rel="tag">testing</a><br />					Раздел: <a href="../../../category/translations/index.html" title="Просмотреть все записи в рубрике &laquo;переводы&raquo;" rel="category tag">переводы</a>&nbsp;&nbsp;|&nbsp;
					<a href="../../../1174/trackback.html#comments" title="Комментарий к записи Еще о тестировании Cluster-mode в SPC-1">Комментарии (7)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1171">
				<h2 class="posttitle"><a href="../../../1171/trackback.html" rel="bookmark" title="Permanent Link to Infinite Volume">Infinite Volume</a></h2>
				<div class="postmetadata">21 Июнь 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Несмотря на то, что современные <em>модные тенденции</em> в софтостроении требуют выпускать новую мажорную версию при списке whatsnew: <em>[*] исправлена грамматическая ошибка в панели About программы</em>, NetApp все же следует классической модели именования&#160; изменения версий. Однако иногда эта консервативность, на мой взгляд, бывает даже чрезмерна, так, напрмер, между Data ONTAP 8.1 и 8.1.1 в функцональность были добавлены весьма существенные, важные и интересные штуки (про одну из них – Flash Pool мы уже говорили ранее). Так, например, это фича, под названием Infinite Volume. Не то чтобы это была сверхнужная для каждого возможность, но тема любопытная, и, возможно, читателям будет интересно узнать, чем же там занимаются, за закрытыми дверями отдела разработки Data ONTAP, и в какую сторону идет направление работ.</p>
<p>Infinite Volume – это новая возможность для кластерных систем (под Cluster-mode) NetApp, позволяющая строить <strong>очень большие</strong> тома, с доступом по NFS v3. На сегодня лимит для Infinite Volume это 20PB и 2 миллиарда файлов в одном “томе”, то есть в одном маунте (экспорте) NFS, на 10-нодовом кластере. Разумеется эти файлы распределены по множеству томов и aggregates нод кластера, но монтируются они при этом через одну точку монтирования. Таким образом, например, 200 томов по 100TB каждый, по 20 томов на каждой из 10 нод кластерной системы, будут смонтированы на сервера по единственному пути cluster:/vol/infivolume/, а не в виде 200 экспортов, на каждом из множества frontend-серверов системы, как это бы пришлось делать в “классическом” варианте.</p>
<p>Infinite Volume, как вы понимаете, это достаточно специализированное решение, ориентрованное на задачи секвентального чтения больших файлов, и сравнительно редкой их записи. Мне видится, что это задача похожа на что-то типа Youtube, или сходного функционала онлайнового файлового или видеохранилища, что-то такое, где себя сейчас хорошо чувствует EMC Isilon. Infinite Volume занимает нишу, в настоящий момент незакрытого в продуктах компании участка, разделяющего задачи систем E-series (бывших LSI/Engenio) и решений на его базе, подобных NetApp FMV solution и прочих StorNext с одной стороны, и “классических” FAS в Cluster-mode с другой.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="../../811.html" rel="tag">8.1.1</a>, <a href="../index.html" rel="tag">cluster-mode</a>, <a href="../../infinite-volume.html" rel="tag">infinite volume</a>, <a href="../../netapp/index.html" rel="tag">netapp</a><br />					Раздел: <a href="../../../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>,  <a href="../../../category/news/index.html" title="Просмотреть все записи в рубрике &laquo;новости&raquo;" rel="category tag">новости</a>&nbsp;&nbsp;|&nbsp;
					<a href="../../../1171/trackback.html#comments" title="Комментарий к записи Infinite Volume">1 комментарий</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1124">
				<h2 class="posttitle"><a href="../../../1124/trackback.html" rel="bookmark" title="Permanent Link to Организация работы с данными в 8.x Cluster-mode">Организация работы с данными в 8.x Cluster-mode</a></h2>
				<div class="postmetadata">27 Февраль 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>??так, в постах о том, как работает Cluster-mode я уже упоминал то, как работает доступ к данным на кластере. А сейчас давайте рассмотрим подробнее процесс создания LUN-а на кластере, для обычного блочного подключения его с хост-сервера Windows.</p>
<p>Несмотря на то, что System Manager 2.0 уже умеет работать с системами в Cluster-mode, мы посмотрим на то, как создаются объекты хранения данных Data ONTAP 8.1 Cluster-mode из консоли. Это нагляднее и проще заскриншотить.</p>
<p>Создадим Vserver. В предыдущем посте я рассказывал что это и зачем нужно в Cluster-mode. А вот как он создается.</p>
<p>Создадим Vserver под названием MyVserver на aggregate с именем aggr1:</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14481/fig1_2012jan27.PNG" /></p>
<p>Допустим, мы хотим обращаться к данным, хранимым на MyVserver по протоколу FCP, для версии 8.1 у нас уже есть возможность работать с данными в Cluster-mode по блочным протоколам. Для этого, включим для Vserver протокол FCP (и проверим его включение):</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14482/fig2_2012jan27.PNG" /></p>
<p>Target Name это физическое имя (nodename) соответствующего контроллера.</p>
<p>Далее нам нужно создать так называемый LIF – Logical Interface, о котором я уже также упоминал в посте ранее. LIF – это логический интерфейс, который динамически мапится на физический интерфейс того или иного узла кластера, на котором работает Vserver, и через который обеспечивается ввод-вывод данных. Создадим и посмотрим на то, что у нас получилось.</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14483/fig3_2012jan27.PNG" /></p>
<p>Network Address/Mask эквивалентен физическому WWPN у порта контроллера.</p>
<p>Создадим igroup – специальную группу, в которую включим нужные нам сервера, чтобы ограничить доступ и видимость LUN-ов только необходимыми серверами. Для этого нам понадобится знать имена WWPN тех портов серверов, которых мы назначим в группу, именно по WWPN и будем определять, наш сервер это или нет.</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14484/fig4_2012jan27.PNG" /></p>
<p>Создадим группу MyIGroup и включим туда FCP WWPN initiator-ов с соответствующих портов.</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14485/fig5_2012jan27.PNG" /></p>
<p>Наконец, создадим том FlexVol под названием MyVol:</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14486/fig6_2012jan27.PNG" /></p>
<p>Теперь создадим LUN по имени MyLUN на этом томе:</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14489/fig7_2012jan27.PNG" /></p>
<p>Смапим LUN соответствующей igroup</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14487/fig8_2012jan27.PNG" /></p>
<p>А теперь подключаем созданный LUN обычным образом на сервер Windows, с помощью стандартной оснастки Disk Management.</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7877-14488/fig9_2012jan27.PNG" /></p>
<p>Готово. У нас на сервере подключен LUN по FCP, расположенный в кластере контроллеров NetApp под управлением Data ONTAP 8.1 Cluster-mode.</p>
<p>За основу поста взят <a href="https://communities.netapp.com/community/netapp-blogs/pseudo_benchmark/blog/2012/01/28/serving-data-in-cluster-mode">пост</a> из блога специалиста NetApp “Pseudo Benchmark”, из которого я позаимствовал скриншоты.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="../../81.html" rel="tag">8.1</a>, <a href="../index.html" rel="tag">cluster-mode</a>, <a href="../../howto/index.html" rel="tag">howto</a>, <a href="../../netapp/index.html" rel="tag">netapp</a>, <a href="../../vserver.html" rel="tag">vserver</a><br />					Раздел: <a href="../../../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<a href="../../../1124/trackback.html#comments" title="Комментарий к записи Организация работы с данными в 8.x Cluster-mode">Комментарии (2)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1117">
				<h2 class="posttitle"><a href="../../../1117/trackback.html" rel="bookmark" title="Permanent Link to Снэпшоты в DOT8.x Cluster-mode">Снэпшоты в DOT8.x Cluster-mode</a></h2>
				<div class="postmetadata">9 Февраль 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Также как и в Data ONTAP 7-mode, в Cluster-mode с версии 8.1 есть снэпшоты. Сохранились все привычные пользователям NetApp команды snap reserve, snap sched, snap list, но добавилось несколько новых команд и возможностей.</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7858-14445/fig1.PNG" /></p>
<p>Также добавились некоторые дополнительные опции в некоторых командах</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7858-14446/fig2.PNG" /></p>
<p>Также есть изменения и в способе задания распсания снэпшотов. Если раньше это делалось командой snap sched, указывалост имя тома и задавались интервалы в формате cron, то новый механизм использует политики (policy), которые управляются командами add-schedule, modify-schedule и remove-schedule. Для создания же новой политики взятия снэпшотов воспользуйтесь командой snap policy create.</p>
<p><img src="https://communities.netapp.com/servlet/JiveServlet/showImage/38-7858-14447/fig3.PNG" /></p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="../../81.html" rel="tag">8.1</a>, <a href="../index.html" rel="tag">cluster-mode</a>, <a href="../../netapp/index.html" rel="tag">netapp</a>, <a href="../../snapshots.html" rel="tag">snapshots</a><br />					Раздел: <a href="../../../category/howto/index.html" title="Просмотреть все записи в рубрике &laquo;howto&raquo;" rel="category tag">howto</a>,  <a href="../../../category/review/index.html" title="Просмотреть все записи в рубрике &laquo;review&raquo;" rel="category tag">review</a>&nbsp;&nbsp;|&nbsp;
					<a href="../../../1117/trackback.html#respond" title="Комментарий к записи Снэпшоты в DOT8.x Cluster-mode">Комментарий</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1118">
				<h2 class="posttitle"><a href="../../../1118/trackback.html" rel="bookmark" title="Permanent Link to Data ONTAP 8.x Cluster-mode: подробнее">Data ONTAP 8.x Cluster-mode: подробнее</a></h2>
				<div class="postmetadata">6 Февраль 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>??так, в прошлом посте этой темы я вкратце остановился на предыстории Data ONTAP 8.x Cluster-mode.</p>
<p>Еще в прошлом году я перестал в этом блоге называть “классическую” структуру из двух контроллеров в системах хранения NetApp “кластером”, с тем, чтобы вам было проще “переключиться”. Пару контроллеров под управлением Data ONTAP 7.x и Data ONTAP 8.x 7-mode следует правильно называть HA-pair (HA – High Availability), HA-парой, или, в крайнем случае, HA-кластером, ясно отделяя это от “кластера” в 8.x Cluster-mode. Словом “кластер” у NetApp теперь называется совсем иная структура. Дабы не путаться, буду следовать этому правилу именования и я.</p>
<p>В настоящий момент можно построить кластер, работающий как NAS-сервер (NFS или CIFS) из 24 узлов-контроллеров (nodes), то есть из 12 <strong>HA-пар</strong> контроллеров.</p>
<p>В версии Data ONTAP 8.1 появлась также поддержка блочных протоколов (iSCSI, FC, FCoE). Однако при использовании блочных протоколов (только их одних, или в комбинации с NAS) максимальный размер кластера на сегодня поддерживается в размере <strong>четырех нод</strong>, или <strong>двух HA-пар</strong>. Эта величина, как я думаю, будет расти, как только будет все отлажено и обеспечена надежность, все же 8.1 это первая версия с такой функциональностью, но пока – имейте это ввиду. Связано это, прежде всего, с тем, что файловые протоколы, такие как NFS или CIFS, по сути, полностью управляются и контролируются на стороне стораджа, и проще обеспечить все необходимые процедуры работы и синхронизацию процессов между узлами кластера.</p>
<p>Прежде всего, следует осознать разницу, между понятиями <strong>Global Filesystem</strong> и <strong>Global Namespace</strong>.&#160; Data ONTAP 8.1 Cluster-mode это Global Namespace, но <strong><font color="#ff0000">НЕ</font></strong> Global Filesystem.     <br />Global Namespace позволяет вам видеть кластер и его пространство, как совокупность нодов его составляющих, как единую “сущность”, целостное пространство, вне зависимости от того где и как хранятся ваши данные. Однако с точки зрения хранения, каждый нод-контроллер, по-прежнему оперирует данными, хранящимися на его aggregates и томах. Один единственный файл <strong>не может</strong> располагаться более чем на одном aggregate/ноде-контроллере. Также он не может мигрировать, распределяясь частью на одном, частью на другом ноде-контроллере. </p>
<p>Это, как мне кажется, очень важно понимать, поэтому на этом я так заостряюсь.</p>
<p>Безусловно, устройства, реализующие Global Filesystem, имеют в этом месте меньше ограничений (например EMC Isilon с его OneFS это как раз Global Filesystem), однако, в нашем мире, как вы помните, ничего не дается бесплатно, и реализация Global Filesystem влечет за собой ряд весьма неприятных побочных негативных эффектов, в первую очередь для производтельности. Isilon весьма хорош, но он хорош на определенных типах рабочей нагрузки (преимущественно последовательном доступе). Насколько в вашем конкретном случае важна возможность хранить огромного размера файл(ы), превосходящие по размерам емкость дисков, подключенных к одному контроллеру, и распределенные на несколько узлов кластера, и готовы ли вы за такую возможность заплатить ухудшением характеристик рандомного доступа к ним – решать вам. На сегодня на рынке имеется как тот, так и другой вариант.</p>
<p>Преимущество же в производительности довольно убедительно показал NetApp в недавнем тестировании SPECsfs2008 на протоколе NFS, где 24-нодовая система FAS6240 под управлением Data ONTAP 8.1, почти в полтора раза превзошла 140-нодовую систему EMC Isilon S200.</p>
<p>При этом, следует отметить, что, в случае NetApp, тестировался <em>worst case</em>, “наихудший случай” то есть только 1/24 часть всех операций шла на контроллер-owner, 23 из каждых 24 операций шли через “неродные” контроллеры, через cluster network, и не использовались никакие существующие у NetApp средства оптимизации, такие как, например, <em>Load Sharing Mirrors</em> (RO-копии) на “неродных” узлах кластера, которые, безусловно, увеличат производительность в реальной жизни.</p>
<p>Напомню, что тест SPECsfs2008 это классический и авторитетный тест, имитрирующий усредненный типовой файловый доступ по протоколам NFS (и CIFS), сгенерированной смесью операций соответствующего протокола, и там, понятное дело, много операций с метаданными и, преимущественно, рандомный доступ.</p>
<p>??так – Data ONTAP 8.1 Cluster-mode это Global Storage Namespace, но <strong>НЕ</strong> Global Storage Filesystem. Несмотря на то, что вы видите кластер как единую сущность, отдельный файл, на нем хранимый <strong>не может</strong> превышать емкость аггрегейта одного контроллера. Однако вы <strong>можете</strong> получать доступ к данным этого файла через любой из контроллеров кластера. В этом заключается разница между Global Filesystem и Global Namespace.</p>
<p>Второй момент, на котором мне хочется подробнее остановится, это то, как именно строится кластер физически. </p>
<p>Несмотря на то, что, формально, “единицей измерения” размера кластера является одна нода, представляющая собой один физический контроллер, ноды эти всегда включены в HA-пары. По этой причине количество нодов в кластере NetApp Data ONTAP 8.x Cluster-mode всегда четное. Таким образом обеспечивается надежность и высокая доступность (High Availability) ноды, тем же методом, как это делалось для контроллеров в 7.x.</p>
<p>Поэтому вы не можете сделать 5- или 15-нодовый кластер, а 4-, 6- или 16-нодовый можете.</p>
<p>Третий момент, который мне бы хотелось подробнее осветить, есть то, что в настоящий момент NetApp предъявляет довольно строгие требования к оборудованию для реализации кластерных коммуникаций. Для построения Cluster network, то есть внутренней сети самого кластера, в настоящий момент поддерживаются только две модели 10-Gigabit коммутаторов, это Cisco Nexus 5010 (20 портов, кластер до 12/18 нодов) и Cisco Nexus 5020 (40 портов, кластер более 18 нодов), их продает NetApp со своими партномерами, в составе общей квотации такой системы. Причем использовать эти коммутаторы можно <strong>только под задачи внутренней кластерной сети</strong>, совмещать их с другими задачами, например для подключения в них клиентской сети – <strong>нельзя</strong>. Даже если там еще остались порты.</p>
<p>Однако есть и хорошая новость. Сейчас NetApp и Cisco, в качестве time-limited promotion, при заказе cluster-mode стораджа у NetApp, отдает необходимое инфраструктурное оборудование за символическую цену 1$ за Cisco Nexus для Cluster network и Cisco Catalyst 2960 для Cluster management network, плюс необходимые SFP и кабеля. При этом цена на систему Data ONTAP 8.1 Cluster-mode из двух нодов, для промоушна, уравнена с ценой аналогичной конфигурации 7-mode, а инфраструктурная часть придет по цене 5$, за пять девайсов (два Nexus 5010, два Catalyst 2960, сет кабелей), плюс сервисные платежи. </p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/Data-ONTAP-8.x-Cluster-mode-_A656/image.png" width="716" height="278" /></p>
<p>Прежде чем у вас как следуют загорятся глаза и затрясутся руки “купить Нексус 5010 за один бакс”, я бы хотел отдельной строкой уточнить, что это предложение действует <strong>только для покупки системы cluster-mode, и, по условиям покупки, не может использоваться ни для чего другого</strong>.</p>
<p>Купленную по промоушну систему на две ноды можно расширить до 12 нодов (6 HA-pair) докупая только SFP и кабеля.</p>
<p>Структура cluster-mode кластера такова (на рисунке, для примера, показана двухузловая система):</p>
<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="cluster-mode scheme" border="0" alt="cluster-mode scheme" src="/pics/Data-ONTAP-8.x-Cluster-mode-_A656/cluster-mode-scheme.png" width="614" height="458" /></p>
<p>В качестве <strong>коммутаторов клиентской сети</strong> можно использовать любые коммутаторы, Ethernet или FC, в зависимости от потребностей пользователя.</p>
<p>В качестве <strong>коммутаторов Cluster network switch</strong> могут использоваться только Cisco Nexus 5010 (для кластеров с числом нод до 12/18) или 5020 (для большего числа нод).</p>
<p>В качестве <strong>Cluster Management Switch</strong> NetApp рекомендует Cisco Catalyst 2960, но, в настоящее время, не обязывает покупать именно эту модель, при необходимости использовать имеющуюся у клиента иную модель, это может быть оформлено через заведение PVR, специального запроса на проверку и аппрув конфигурации у NetApp. NB: SMARTnet для такого свитча – обязателен!</p>
<p>Cluster Network это выделенная только под эту задачу сеть 10Gb Ethernet. Единственное исключение – FAS2040, которая может использоваться в Cluster-mode с использованием Gigabit Ethernet, но не рекомендуется ее использование с другими контроллерами. Обратите внимание, что даже для 2040 и ее Gigabit Ethernet, <strong>другие коммутаторы, кроме Nexus 5010/5020, не поддерживаются!</strong></p>
<p>Ноды кластера <strong>могут</strong> быть различными по модели. Вы можете объединить в единый кластер любые контроллеры, для которых объявлена совместимость с cluster-mode (с единственным исключением в виде FAS2040, использование которого с контроллерами другого типа не рекомендуется (хотя и возможно), по вышеописанной причине отсутствия портов 10G)</p>
<p>Вы также можете объединить в кластер и системы с дисками различных типов, например вы можете построить систему с дисками SAS, SATA и SSD в рамках одного единого кластера, и организовывать миграцию данных между разными колнтроллерами-нодами и дисками разных типов.</p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/Data-ONTAP-8.x-Cluster-mode-_A656/image_3.png" width="480" height="348" /></p>
<p>&#160;</p>
<p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="/pics/Data-ONTAP-8.x-Cluster-mode-_A656/image_4.png" width="451" height="353" /></p>
<p>Далее кратко и бегло:</p>
<p><strong>Какие контроллеры в настоящее время поддерживаются для работы в Cluster-mode?</strong></p>
<p>FAS/V62&#215;0, FAS60&#215;0, FAS/V32&#215;0, FAS31&#215;0, FAS3070, FAS3040, FAS2240, и FAS2040.    <br />Для 2040 есть ограничения, связанные с отсутствием 10G Ethernet, для 3040 и 3070 ограничено максимальное количество нодов в использующих их кластеров. Помните, что для работы Cluster-mode <strong>нужна</strong> пара портов 10G Ethernet и несколько дополнительных портов для сетевых интерфейсов cluster management и сети собственно доступа к данных с клиентов.</p>
<p><strong>Какие возможности “традиционной” Data ONTAP 7-mode поддерживаются, и какие – не поддерживаются?</strong></p>
<p><strong><font color="#008000">Поддерживаются:</font></strong></p>
<ul>
<li>Доступ к данным по:
<ul>
<li>файловым протоколам (NFSv3, NFSv4, NFSv4.1/pNFS, CIFS(SMB1.0), SMB2.0 и SMB2.1), c размером кластера до 24 нодов. </li>
<li>по блочным протоколам (iSCSI, FC, FCoE), с размером кластера до 4 нодов (кроме FAS2040, FAS3040/3070 и FAS6030/6070, для них SAN в cluster-mode не поддерживается) . </li>
</ul>
</li>
<li>Репликация SnapMirror – только асинхронная и только Volume SnapMirror. Репликация совместима только между системами Cluster-mode. </li>
<li>Снэпшоты </li>
<li>Компрессия и дедупликация </li>
<li>FlexClone </li>
<li>NDMP </li>
</ul>
<p><strong><font color="#ff0000">Не поддерживаются:</font></strong></p>
<ul>
<li>Синхронный SnapMirror, Qtree SnapMirror (сами qtree как объект иерархии поддерживаются), SnapMirror между системами 7-mode и cluster-mode </li>
<li>SyncMirror </li>
<li>Metrocluster </li>
<li>SnapVault </li>
<li>SnapLock </li>
<li>IPv6 </li>
</ul>
<p><strong>Каковы основные преимущества и цели системы Cluster-mode?</strong></p>
<ul>
<li>Балансировка и масштабирование для больших нагрузок </li>
<li>Непрерывающее работу наращивание производительности и миграция данных </li>
<li>Единая, с точки зрения управления и администрирования “сущность” – кластер нодов. </li>
<li>Поддержка привычных средств и фич NetApp – RAID-DP, FlexClone, Snapshots, SnapMirror Async, дедупликация, компрессия. </li>
</ul>
<p><strong>Что такое Vserver?</strong></p>
<p>Оставайтес с нами, об этом – в следующих постах :)</p>
<p><strong>Есть/будет ли FlexPod под Cluster-mode?</strong></p>
<p>Пока – нет, но, возможно, будет.</p>
<p><strong>Какие диски и полки поддерживаются?</strong></p>
<p>Все, любые существующие на сегодня в продаже (не поддерживается интерфейсный модуль ESH2 и еще более старые).</p>
<p><strong>Можно ли включать в кластер системы V-series и сторонние стораджи через них?</strong></p>
<p>Да, можно V3200/6200 c EMC DMX4, CX4 и HP EVA. Остальные, может быть, через PVR. Однако даже для перечисленных систем нужна полка с дисками NetApp для хранения root volume.</p>
<p><strong>Каков максимальный размер aggregate?</strong></p>
<ul>
<li>2040/3040/3070 – 50TiB </li>
<li>2240 – 60TiB </li>
<li>3210/3140 – 75TiB </li>
<li>6030/6040/3270/3170 – 105TiB </li>
<li>6070/6080/6210/6240/6280 – 162TiB </li>
</ul>
<p><strong>Каков максимальный размер тома?</strong></p>
<p>Как максимальный размер 64-bit aggregate в 7-mode для соответствующих контроллеров</p>
<p><strong>Каково максимальное расстояние “разноса” нодов кластера?</strong></p>
<p>Максимальное допустимое расстояние от ноды до коммутатора cluster network – 300 метров.   <br />Расстояние между redundant коммутаторами cluster network – 300 метров.    <br />Расстояние между двумя нодами в HA-паре – то же, что и для 7-mode.</p>
<p><strong>FlashCache поддерживается?</strong></p>
<p>Да!</p>
<p><strong>Есть ли <em>non-disruptive upgrade</em> для систем 7-Mode?</strong></p>
<p>К сожалению – нет. Только через полную разборку-сборку.</p>
<p><strong>Есть ли <em>non-disruptive expand</em> или <em>reduce </em>для кластера новыми нодами?</strong></p>
<p>Да.</p>
<p><strong>Можно ли слить вместе два кластера?</strong></p>
<p><em>В настоящий момент</em> нет, только через копирование, разборку второго и добавление его нод.</p>
<p><strong>Нужен ли коммутатор для Cluster network в случае использования всего двух нод в кластере?</strong></p>
<p>Да, все равно нужен даже для всего двух нод.</p>
<p><strong>Работают-ли на Cluster-mode системах дедупликация, компрессия, thin provisioning, снэпшоты?</strong></p>
<p>Да, все это работает.</p>
<p><strong>Каким образом можно управлять кластером в Cluster-mode?</strong></p>
<ul>
<li>GUI: NetApp System Manager 2.0 </li>
<li>CLI: SSH к кластеру, ноде или Vserver </li>
<li>OnCommand 5.0 </li>
<li>NetApp Management SDK </li>
</ul>
<p>FilerView (web-интерфейс, встроенный в контроллер) начиная с 8.1 <em>не поддерживается</em>.</p>
<p><strong>Должен ли я управлять каждой нодой в отдельности?</strong></p>
<p>Нет, кластер управляется как целостная сущность, без разделения на ноды. Каждая нода, при включении в кластер, получает и наследует глобальные настройки данного кластера.</p>
<p><strong>Как обеспечивается антивирусная защита хранимых данных для кластера?</strong></p>
<p>Тадааам! Теперь у Data ONTAP есть встроенный в OS движок антивирусного контроля и защиты. В настоящий момент лицензированы продукты Sophos и McAfee</p>
<p>&#160;</p>
<p>Больше о работе и управлении в кластере – в следующем посте этой серии.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="../../81.html" rel="tag">8.1</a>, <a href="../index.html" rel="tag">cluster-mode</a>, <a href="../../netapp/index.html" rel="tag">netapp</a><br />					Раздел: <a href="../../../category/review/index.html" title="Просмотреть все записи в рубрике &laquo;review&raquo;" rel="category tag">review</a>,  <a href="../../../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<a href="../../../1118/trackback.html#comments" title="Комментарий к записи Data ONTAP 8.x Cluster-mode: подробнее">Комментарии (5)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1113">
				<h2 class="posttitle"><a href="../../../1113/trackback.html" rel="bookmark" title="Permanent Link to Data ONTAP 8.x Cluster-mode">Data ONTAP 8.x Cluster-mode</a></h2>
				<div class="postmetadata">30 Январь 2012, 20:07 <!-- от  --></div>
				<div class="postentry">
					<p>Этот год для компании NetApp станет, без сомнения, “годом cluster-mode”. Наконец-то этот режим “дозрел” до широкого рынка, и в этом году, я надеюсь, мы увидим активность во внедрении именно этой, до сих пор для массового пользователя остававшейся в тени, но весьма многообещающей возможности систем хранения NetApp.</p>
<p>Для начала же несколько слов о том, что такое Data ONTAP Cluster-mode, и чем он отличается от привычного Data ONTAP 7-mode в HA-кластере.</p>
<p>Еще в 2003 году NetApp купила стартап Spinnaker, занимавшийся разработками в области кластерных файловых систем и системы Global Namespace, и несколько лет спустя выпустила на рынок специальную OS, под названием Data ONTAP 10. Это была специальная OS для систем NetApp, позволявшая строить многоузловые кластеры хранения данных. К сожалению, она имела множество ограничений, в частности, работала только как NFS-сервер, и не имела множества важных и привычных возможностей “классической” Data ONTAP 7.x, поэтому особой популярности не завоевала, была дорогой, ограниченной, требовавшей значительных специальных знаний для запуска и использования, и, в результате, ее использование было ограничено рынком высокопроизводительных файловых серверов для HPC (High-performance Computing) и систем хранения научной и аудио-видео информации. Общее число клиентов в мире, использовавших Data ONTAP 10, не превышало пары сотен.</p>
<p>Следующим шагом NetApp, стала попытка объединить, “слить” две эти OS в одну. Однако объявленное в 2008 году “слияние” оказалось в значительной степени “фиктивным”, просто из одного дистрибутива OS, получившей название Data ONTAP 8.x стало возможным установить две OS: либо в режиме 7-mode, то есть “классической” Data ONTAP, либо в режиме, получившем название “Cluster-mode”, и явившемся развитием Data ONTAP 10. К сожалению это были, как я сказал выше, просто две OS, ставившихся из одного дистрибутива, и только. В Cluster-mode не появились привычные возможности Data ONTAP Classic, и по-прежнему это были две несовместимые OS, не имевшие возможности миграции данных или взаимодействия, полностью отличавшихся по структурам хранения данных и работе с ними. </p>
<p>Вследствие этого, имеющиеся пара сотен клиентов DOT10 были переведены на 8.x Cluster-mode, а основная масса пользователей систем NetApp по прежнему продолжала пользоваться “7-mode”. Значительным барьером, кроме функциональных ограничений, была и цена, а также сложность реализации.</p>
<p>Однако работы продолжались, и, постепенно, в 8.x Cluster-mode стали появляться привычные для 7-mode возможности, такие как репликация, блочная дедупликация, а также, что более всего важно, работа с блочными протоколами – FC, iSCSI и FCoE. Напомню, что, до версии 8.1, Cluster-mode была чисто “файловым хранилищем”, работающем по протоколам NFS и CIFS, что устраивало не всех.</p>
<p>Тем временем, как NetApp “переваривала” наследство Spinnaker, на рынке стали появляться конкуренты в данной области, так активно стал продаваться (и в итоге продался целиком EMC) продукт компании Isilon, а растущий интерес к “облачным” IT-системам естественным образом стал “локомотивом” развития и “облаков” хранения - многоузловых кластеров.</p>
<p>??так, начиная с версии Data ONTAP 8.1 версия Cluster-mode стала уметь работать с блочными SAN-протоколами, стала уметь асинхронную репликацию и снэпшоты, привычные для Data ONTAP Classic, дедупликацию и компрессию, наконец, были снижены цены, и использование Cluster-mode стало несколько более доступным для пользователей.</p>
<p>Настала пора и в этом блоге поподробнее поговорить о том, что же такое Cluster-mode, как его можно использовать, и чем он может вам пригодиться. В этом году, я надеюсь, я буду говорить о Data ONTAP 8.x Cluster-mode куда чаще. В ближайшие несколько постов я намерен рассказать подробнее о том, что сегодня представляет собой Cluster-mode, и как это выглядит на практике.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="../../81.html" rel="tag">8.1</a>, <a href="../index.html" rel="tag">cluster-mode</a>, <a href="../../netapp/index.html" rel="tag">netapp</a><br />					Раздел: <a href="../../../category/justread/index.html" title="Просмотреть все записи в рубрике &laquo;justread&raquo;" rel="category tag">justread</a>&nbsp;&nbsp;|&nbsp;
					<a href="../../../1113/trackback.html#comments" title="Комментарий к записи Data ONTAP 8.x Cluster-mode">1 комментарий</a>									 </div>
			</div>
	
		
		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"><a href="../index.html">Next Entries &raquo;</a></div>
		</div>
		
	
	</div>
	<div id="sidebar">
		<ul>
			
			
			<!-- Author information is disabled per default. Uncomment and fill in your details if you want to use it.
			<li><h2>Автор</h2>
			<p>A little something about you, the author. Nothing lengthy, just an overview.</p>
			</li>
			-->

			<li class="pagenav"><h2>Страницы</h2><ul><li class="page_item page-item-153"><a href="../../../../about/trackback.html" title="about">about</a></li>
<li class="page_item page-item-215"><a href="../../../../distributory-v-rossii/trackback.html" title="Дистрибуторы в России">Дистрибуторы в России</a></li>
<li class="page_item page-item-1327"><a href="../../../../disti-ua/trackback.html" title="Дистрибуторы в Украине">Дистрибуторы в Украине</a></li>
</ul></li>
			<li><h2>Рубрики</h2>
				<ul>
					<li class="cat-item cat-item-89"><a href="../../../category/commands/index.html" title="Просмотреть все записи в рубрике &laquo;commands&raquo;">commands</a>
</li>
	<li class="cat-item cat-item-37"><a href="../../../category/howto/index.html" title="Просмотреть все записи в рубрике &laquo;howto&raquo;">howto</a>
</li>
	<li class="cat-item cat-item-52"><a href="../../../category/justread/index.html" title="Просмотреть все записи в рубрике &laquo;justread&raquo;">justread</a>
</li>
	<li class="cat-item cat-item-51"><a href="../../../category/review/index.html" title="Просмотреть все записи в рубрике &laquo;review&raquo;">review</a>
</li>
	<li class="cat-item cat-item-3"><a href="../../../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;">techtalk</a>
</li>
	<li class="cat-item cat-item-71"><a href="../../../category/tricks/index.html" title="Просмотреть все записи в рубрике &laquo;tricks&raquo;">tricks</a>
</li>
	<li class="cat-item cat-item-95"><a href="../../../category/utilities/index.html" title="Просмотреть все записи в рубрике &laquo;utilities&raquo;">utilities</a>
</li>
	<li class="cat-item cat-item-44"><a href="../../../category/whoisho/index.html" title="Просмотреть все записи в рубрике &laquo;whoisho&raquo;">whoisho</a>
</li>
	<li class="cat-item cat-item-1"><a href="../../../category/news/index.html" title="Просмотреть все записи в рубрике &laquo;новости&raquo;">новости</a>
</li>
	<li class="cat-item cat-item-387"><a href="../../../category/opros.html" title="Просмотреть все записи в рубрике &laquo;опрос&raquo;">опрос</a>
</li>
	<li class="cat-item cat-item-8"><a href="../../../category/translations/index.html" title="Просмотреть все записи в рубрике &laquo;переводы&raquo;">переводы</a>
</li>
	<li class="cat-item cat-item-40"><a href="../../../category/citaty/index.html" title="Просмотреть все записи в рубрике &laquo;цитаты&raquo;">цитаты</a>
</li>
				</ul>
			</li>

			<li><h2>Архивы</h2>
				<ul>
					<li><a href='../../../date/2018/01.html' title='Январь 2018'>Январь 2018</a></li>
	<li><a href='../../../date/2015/10.html' title='Октябрь 2015'>Октябрь 2015</a></li>
	<li><a href='../../../date/2015/04.html' title='Апрель 2015'>Апрель 2015</a></li>
	<li><a href='../../../date/2015/03.html' title='Март 2015'>Март 2015</a></li>
	<li><a href='../../../date/2015/01.html' title='Январь 2015'>Январь 2015</a></li>
	<li><a href='../../../date/2014/12.html' title='Декабрь 2014'>Декабрь 2014</a></li>
	<li><a href='../../../date/2014/11.html' title='Ноябрь 2014'>Ноябрь 2014</a></li>
	<li><a href='../../../date/2014/10.html' title='Октябрь 2014'>Октябрь 2014</a></li>
	<li><a href='../../../date/2014/09.html' title='Сентябрь 2014'>Сентябрь 2014</a></li>
	<li><a href='../../../date/2014/08.html' title='Август 2014'>Август 2014</a></li>
	<li><a href='../../../date/2014/07.html' title='Июль 2014'>Июль 2014</a></li>
	<li><a href='../../../date/2014/06.html' title='Июнь 2014'>Июнь 2014</a></li>
	<li><a href='../../../date/2014/05.html' title='Май 2014'>Май 2014</a></li>
	<li><a href='../../../date/2014/04.html' title='Апрель 2014'>Апрель 2014</a></li>
	<li><a href='../../../date/2014/03.html' title='Март 2014'>Март 2014</a></li>
	<li><a href='../../../date/2014/02.html' title='Февраль 2014'>Февраль 2014</a></li>
	<li><a href='../../../date/2014/01.html' title='Январь 2014'>Январь 2014</a></li>
	<li><a href='../../../date/2013/12.html' title='Декабрь 2013'>Декабрь 2013</a></li>
	<li><a href='../../../date/2013/11.html' title='Ноябрь 2013'>Ноябрь 2013</a></li>
	<li><a href='../../../date/2013/10.html' title='Октябрь 2013'>Октябрь 2013</a></li>
	<li><a href='../../../date/2013/09.html' title='Сентябрь 2013'>Сентябрь 2013</a></li>
	<li><a href='../../../date/2013/08.html' title='Август 2013'>Август 2013</a></li>
	<li><a href='../../../date/2013/07.html' title='Июль 2013'>Июль 2013</a></li>
	<li><a href='../../../date/2013/06.html' title='Июнь 2013'>Июнь 2013</a></li>
	<li><a href='../../../date/2013/05.html' title='Май 2013'>Май 2013</a></li>
	<li><a href='../../../date/2013/04.html' title='Апрель 2013'>Апрель 2013</a></li>
	<li><a href='../../../date/2013/03.html' title='Март 2013'>Март 2013</a></li>
	<li><a href='../../../date/2013/02.html' title='Февраль 2013'>Февраль 2013</a></li>
	<li><a href='../../../date/2013/01.html' title='Январь 2013'>Январь 2013</a></li>
	<li><a href='../../../date/2012/12.html' title='Декабрь 2012'>Декабрь 2012</a></li>
	<li><a href='../../../date/2012/11.html' title='Ноябрь 2012'>Ноябрь 2012</a></li>
	<li><a href='../../../date/2012/10.html' title='Октябрь 2012'>Октябрь 2012</a></li>
	<li><a href='../../../date/2012/09.html' title='Сентябрь 2012'>Сентябрь 2012</a></li>
	<li><a href='../../../date/2012/08.html' title='Август 2012'>Август 2012</a></li>
	<li><a href='../../../date/2012/07.html' title='Июль 2012'>Июль 2012</a></li>
	<li><a href='../../../date/2012/06.html' title='Июнь 2012'>Июнь 2012</a></li>
	<li><a href='../../../date/2012/05.html' title='Май 2012'>Май 2012</a></li>
	<li><a href='../../../date/2012/04.html' title='Апрель 2012'>Апрель 2012</a></li>
	<li><a href='../../../date/2012/03.html' title='Март 2012'>Март 2012</a></li>
	<li><a href='../../../date/2012/02.html' title='Февраль 2012'>Февраль 2012</a></li>
	<li><a href='../../../date/2012/01.html' title='Январь 2012'>Январь 2012</a></li>
	<li><a href='../../../date/2011/12.html' title='Декабрь 2011'>Декабрь 2011</a></li>
	<li><a href='../../../date/2011/11.html' title='Ноябрь 2011'>Ноябрь 2011</a></li>
	<li><a href='../../../date/2011/10/index.html' title='Октябрь 2011'>Октябрь 2011</a></li>
	<li><a href='../../../date/2011/09/index.html' title='Сентябрь 2011'>Сентябрь 2011</a></li>
	<li><a href='../../../date/2011/08.html' title='Август 2011'>Август 2011</a></li>
	<li><a href='../../../date/2011/07/index.html' title='Июль 2011'>Июль 2011</a></li>
	<li><a href='../../../date/2011/06/index.html' title='Июнь 2011'>Июнь 2011</a></li>
	<li><a href='../../../date/2011/05/index.html' title='Май 2011'>Май 2011</a></li>
	<li><a href='../../../date/2011/04/index.html' title='Апрель 2011'>Апрель 2011</a></li>
	<li><a href='../../../date/2011/03/index.html' title='Март 2011'>Март 2011</a></li>
	<li><a href='../../../date/2011/02.html' title='Февраль 2011'>Февраль 2011</a></li>
	<li><a href='../../../date/2011/01.html' title='Январь 2011'>Январь 2011</a></li>
	<li><a href='../../../date/2010/12.html' title='Декабрь 2010'>Декабрь 2010</a></li>
	<li><a href='../../../date/2010/11/index.html' title='Ноябрь 2010'>Ноябрь 2010</a></li>
	<li><a href='../../../date/2010/10/index.html' title='Октябрь 2010'>Октябрь 2010</a></li>
	<li><a href='../../../date/2010/09/index.html' title='Сентябрь 2010'>Сентябрь 2010</a></li>
	<li><a href='../../../date/2010/08.html' title='Август 2010'>Август 2010</a></li>
	<li><a href='../../../date/2010/07/index.html' title='Июль 2010'>Июль 2010</a></li>
	<li><a href='../../../date/2010/06.html' title='Июнь 2010'>Июнь 2010</a></li>
	<li><a href='../../../date/2010/05.html' title='Май 2010'>Май 2010</a></li>
	<li><a href='../../../date/2010/04/index.html' title='Апрель 2010'>Апрель 2010</a></li>
	<li><a href='../../../date/2010/03/index.html' title='Март 2010'>Март 2010</a></li>
	<li><a href='../../../date/2010/02.html' title='Февраль 2010'>Февраль 2010</a></li>
	<li><a href='../../../date/2010/01.html' title='Январь 2010'>Январь 2010</a></li>
	<li><a href='../../../date/2009/12/index.html' title='Декабрь 2009'>Декабрь 2009</a></li>
	<li><a href='../../../date/2009/11/index.html' title='Ноябрь 2009'>Ноябрь 2009</a></li>
	<li><a href='../../../date/2009/10.html' title='Октябрь 2009'>Октябрь 2009</a></li>
	<li><a href='../../../date/2009/09.html' title='Сентябрь 2009'>Сентябрь 2009</a></li>
	<li><a href='../../../date/2009/08/index.html' title='Август 2009'>Август 2009</a></li>
	<li><a href='../../../date/2009/07/index.html' title='Июль 2009'>Июль 2009</a></li>
	<li><a href='../../../date/2009/06.html' title='Июнь 2009'>Июнь 2009</a></li>
	<li><a href='../../../date/2009/05.html' title='Май 2009'>Май 2009</a></li>
	<li><a href='../../../date/2009/04.html' title='Апрель 2009'>Апрель 2009</a></li>
	<li><a href='../../../date/2009/03.html' title='Март 2009'>Март 2009</a></li>
	<li><a href='../../../date/2009/02.html' title='Февраль 2009'>Февраль 2009</a></li>
	<li><a href='../../../date/2009/01.html' title='Январь 2009'>Январь 2009</a></li>
	<li><a href='../../../date/2008/12.html' title='Декабрь 2008'>Декабрь 2008</a></li>
	<li><a href='../../../date/2008/11.html' title='Ноябрь 2008'>Ноябрь 2008</a></li>
	<li><a href='../../../date/2008/10.html' title='Октябрь 2008'>Октябрь 2008</a></li>
	<li><a href='../../../date/2008/09.html' title='Сентябрь 2008'>Сентябрь 2008</a></li>
	<li><a href='../../../date/2008/08.html' title='Август 2008'>Август 2008</a></li>
	<li><a href='../../../date/2008/03.html' title='Март 2008'>Март 2008</a></li>
	<li><a href='../../../date/2008/02.html' title='Февраль 2008'>Февраль 2008</a></li>
	<li><a href='../../../date/2007/12.html' title='Декабрь 2007'>Декабрь 2007</a></li>
	<li><a href='../../../date/2007/11.html' title='Ноябрь 2007'>Ноябрь 2007</a></li>
	<li><a href='../../../date/2007/10.html' title='Октябрь 2007'>Октябрь 2007</a></li>
	<li><a href='../../../date/2007/09.html' title='Сентябрь 2007'>Сентябрь 2007</a></li>
	<li><a href='../../../date/2007/08.html' title='Август 2007'>Август 2007</a></li>
	<li><a href='../../../date/2007/07/index.html' title='Июль 2007'>Июль 2007</a></li>
	<li><a href='../../../date/2007/06.html' title='Июнь 2007'>Июнь 2007</a></li>
	<li><a href='../../../date/2007/05.html' title='Май 2007'>Май 2007</a></li>
				</ul>
			</li>

			
					</ul>
	</div>

</div> <!-- wrapper -->
<div id="footer">
	<a href="../../../../feed">Entries (RSS)</a> and <a href="../../../../comments/feed">Comments (RSS)</a>. Valid <a href="http://validator.w3.org/check/referer" title="This page validates as XHTML 1.0 Transitional"><abbr title="eXtensible HyperText Markup Language">XHTML</abbr></a> and <a href="http://jigsaw.w3.org/css-validator/check/referer"><abbr title="Cascading Style Sheets">CSS</abbr></a>.<br />
	Powered by <a href="http://wordpress.org/" title="Powered by WordPress.">WordPress</a> and <a href="http://srinig.com/wordpress/themes/fluid-blue/">Fluid Blue theme</a>.<br />
	<!-- 15 queries. 0.096 seconds. -->
	</div>
</div> <!-- page -->
</body>
</html>
