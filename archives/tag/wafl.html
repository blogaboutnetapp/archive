<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="ru-RU">

<head profile="http://gmpg.org/xfn/11">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<title>about NetApp   &raquo; wafl</title>

<link rel="stylesheet" href="../../wp-content/themes/fluid-blue/style.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../wp-content/themes/fluid-blue/print.css" type="text/css" media="print" />
<link rel="alternate" type="application/rss+xml" title="about NetApp RSS Feed" href="../../feed" />
<link rel="pingback" href="../../xmlrpc.php.html" />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../xmlrpc.php%3Frsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 2.6" />

</head>

<body>
<div id="page">
<div id="header">
	<div id="headertitle">
		<h1><a href="../../index.html" title="about NetApp: Системы хранения данных как предмет разговора">about NetApp</a></h1>
		<p>Системы хранения данных как предмет разговора</p>
	</div> 
	<!-- Search box (If you prefer having search form as a sidebar widget, remove this block) -->
	<div class="search">
		<form method="get" id="searchform" action="../../index.html">
<input type="text" size="20" name="s" id="s" value="Поиск..."  onblur="if(this.value=='') this.value='Поиск...';" onfocus="if(this.value=='Поиск...') this.value='';"/>
</form>
	</div> 
	<!-- Search ends here-->
		
</div>

<div id="navbar">
<ul id="nav">
	<li><a href="../../index.html">Home</a></li>
	<li class="page_item page-item-153"><a href="../../about/trackback.html" title="about">about</a></li>
<li class="page_item page-item-215"><a href="../../distributory-v-rossii/trackback.html" title="Дистрибуторы в России">Дистрибуторы в России</a></li>
<li class="page_item page-item-1327"><a href="../../disti-ua/trackback.html" title="Дистрибуторы в Украине">Дистрибуторы в Украине</a></li>
</ul>
</div>
<div id="wrapper">

	<div id="content">

	
			<p>Posts tagged &#8216;wafl&#8217;</p>

	 		
		<div class="navigation">
			<div class="alignleft"><a href="wafl/page/2.html">&laquo; Previous Entries</a></div>
			<div class="alignright"></div>
		</div>

						
			<div class="post" id="post-1225">
				<h2 class="posttitle"><a href="../1225/trackback.html" rel="bookmark" title="Permanent Link to В последний раз о фрагментации файлов и производительности">В последний раз о фрагментации файлов и производительности</a></h2>
				<div class="postmetadata">23 Октябрь 2012, 10:56 <!-- от  --></div>
				<div class="postentry">
					<p>Я много раз в этом блоге трогал тему о влиянии фрагментации на производительность работы системы хранения (см. например <a href="../221/trackback.html">раз</a>, <a href="../225/trackback.html">два</a>, <a href="../881/trackback.html">три</a>). Но как-то все это были слова, а как насчет “покажь логи”? Так как я до недавних пор был “безлошадный”, а все мои знакомые “с оборудованием” все как на подбор были “ленивы и нелюбопытны”, чтобы дать документальный ответ на этот вопрос, то поэтому пришлось отвечать самому.</p>
<p>Тут вот, как вы уже заметили, я, наконец, <em>обзавелся на хозяйстве </em>маленьким нетаппчиком, и, пока мы его в продакшн не ввели, гоняю в хвост и в гриву, в том числе <em>отвечаю на назревшие вопросы</em>. ?? первый – о том, влияет ли фрагментация данных на производительность доступа к ним при рандомном характере доступа.</p>
<p>Выше в постах, на которые я сослался, я уже ответил на этот вопрос и прояснил свою позицию. Вкратце: <strong>при рандомном доступе производительность от фрагментации данных не зависит</strong>. Так как система хранения обращается к данным рандомно, в произвольном, случайном порядке, то нет никакой особенной разницы в том, будут ли блоки данных лежать упорядоченно, или беспорядочно – их всегда будут читать “беспорядочно”. А рандомность обращения, помноженная на рандомность размещения не дает “рандомность в квадрате”, она остается обычной рандомностью, “в первой степени”.</p>
<p>Надеюсь не нужно дополнительно объяснять, почему для современных многозадачных систем, для баз OLTP, для виртуализованных серверных сред почти 100% доступа к данным является рандомным? Последовательный, “секвентальный” доступ встречается в очень узком сегменте, это бэкапы (а у NetApp, к слову, задача бэкапа, как вы помните, решается другим способом, а не последовательным копированием и передачей данных), это базы с характером доступа DSS, и это, отчасти, логи баз данных. Вот, в общем, и все использование секвентального доступа. Остальное все – более или менее чистый рандом.</p>
<p>Поэтому я взял паттерн доступа <strong>VM-сервер</strong> (40%-write/60%-read, 45%-sequental/55%-random, 4KB block). Секвентальность в последнем случае берется вследствие работы локального кэша хоста. Паттерны эти определил не я, они довольно широко распространены. Вот его и будем <strike>кушать</strike> мерять.</p>
<p>Тестировал я с помощью IOmeter, который, несмотря на некоторые его недостатки, знаю и люблю. В качестве load-generator использовались виртуальные машины, работающие с достаточно мощного хоста (IBM 3850 X5), который был подключен к стораджу по NFS. Для OS в VM диск выглядел “физическим” LUN без файловой системы, который делался MBR-разделом и форматировался в NTFS со стандартным размером блока (4KB). Раздел делался размером 40GB, на нем создавался тестовый файл IOmeter (iobw.tst), размером 16GB (для гарантированного “пробоя кэша”). На каждой VM делался 4-процессорный vCPU, и, соответственно, запускались 4 Worker, на каждом из которых пускался тестовый паттерн на созданный диск, в 16 потоков ввода-вывода (Outstanding IOs) на каждый Worker, то есть 64 одновременных потока ввода-вывода на диски (контроллер NetApp). Загрузка хост-сервера тестом не превышала при этом 15% (мощная зверюга этот 3850), загрузка стораджа колебалась, но также не превышала 80%. То есть заведомо мы в “потолки” нигде не упирались.</p>
<p>Для минимизации эффектов “прогрева WAFL” (о котором еще будет пост, это также была одна из тем “исследовательской недели”) я делал длинный ramp-up (10 минут), а затем начинался собственно измеряемый тест, длиной 30 минут. Я брал для оценки значение в steady state, ближе к концу теста, и для оценки параллельно проверяемого эффекта “падения производительности” при прогреве – ближе к его началу.</p>
<p>Однако, перед исследователем, в моем лице, встала проблема: как обеспечить “фрагментацию” файла тестирования? Если создать последовательный, упорядоченный файл просто: запускай IOmeter на пустом диске – вот он и создаст свой iobw.tst, то с фрагментацией “на заказ” сложнее.</p>
<p>Для того, чтобы сделать фрагментированный файл я нашел любопытную утилитку, под названием MyDefragmenter, которая, как ясно из названия – дефрагментатор. Но у нее в комплекте есть также программка MyFragmenter :). Она делает вполне ожидаемую из названия вещь :)</p>
<p>Я взял созданный IOmeter тестовый файл и <em>качественно замесил</em> его с помощью этой утилитки. Я фрагментировал с ее помощью этот файл на 250 тысяч кусочков по 64KB каждый (ну, чтоб не было претензий, что <em>гранаты у нас не той системы</em>;), а потом повторно провел тестирование описанными выше паттернами.</p>
<p>Также я проанализировал ситуацию с фрагментацией не только файла на NTFS, но и в WAFL, а затем измерил эффект от работы reallocate в WAFL.</p>
<p>Хочу отдельно отметить, что в данном случае измеренные “попугаи”&#160; не могут рассматриваться по абсолютной величине, я не проводил никакого (необходимого) тюнинга системы, и настройки ее “по уму” и по best practices (это я&#160; сделаю позже, ту у меня есть некоторые бюрократические процедуры для этого). Целью теста было сравнить два достигнутых параметра производительности: “А” и”Б”, то есть их соотношение, а не достижение абсолютного рекорда, поэтому реплики с мест “чота как-то иопсев маловата!” мы отметем как неорганизованные ;).</p>
<p>Вот какие результаты я получил:</p>
<p>   <a href="../1225/trackback.html#more-1225" class="more-link"><small>Continue reading &#8216;В последний раз о фрагментации файлов и производительности&#8217; &raquo;</small></a></p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="fragmentation.html" rel="tag">fragmentation</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="performance/index.html" rel="tag">performance</a>, <a href="reallocate.html" rel="tag">reallocate</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/justread/index.html" title="Просмотреть все записи в рубрике &laquo;justread&raquo;" rel="category tag">justread</a>,  <a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<a href="../1225/trackback.html#comments" title="Комментарий к записи В последний раз о фрагментации файлов и производительности">Комментарии (13)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1137">
				<h2 class="posttitle"><a href="../1137/trackback.html" rel="bookmark" title="Permanent Link to WAFL File Folding">WAFL File Folding</a></h2>
				<div class="postmetadata">5 Апрель 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>О любопытной функции внутри Data ONTAP прочитал недавно в блоге <a href="http://www.ntapgeek.com/2012/03/wafl-file-folding-explained.html">ntapgeek</a>. Эта фича называется WAFL File Folding и позволяет экономить место на дисках для файлов, отдаваемых по протоколу CIFS.</p>
<p>Принцип работы File Folding таков. Как вы уже знаете (а кто не знает – <a href="../39/trackback.html">идите и читайте</a>), все перезаписи данных на WAFL осуществляются, согласно конструкции файловой системы, таким образом, что они не меняют собственно содержимого блока данных в файле, а записываются в отдельный свободный блок, куда переставляется “указатель”-inode. Это позволяет быстро и просто делать снэпшоты, так как в WAFL не нужно, как во всех прочих реалиациях снэпшотов, переносить содержимое перезаписывамых блоков в отдельное место. Единожды записанный блок, помещенный в снэпшот, уже никак не будет изменен, так устроена FS.</p>
<p>Однако представим себе такую странную ситуацию, когда обширный файл, с которого у нас взят снэпшот, перезаписывается, целиком или полностью, ровно теми же данными, что уже лежат в нем. Для каждого блока такого файла на диске будет занято по меньшей мере два физческих блока. Один – оригинальный, лежащий запертым в снэпшоте, и второй – измененный, лежащий в пространстве “активной файловой системы”, даже несмотря на то, что содержимое этих блоков совершенно идентичное.</p>
<p>Я теряюсь в догадках, что это за операция такое проделвывает, но факт того, что это сделано именно для CIFS, подсказывает мне, что что-то в CIFS любит перезаписывать целиком файлы, даже, например, при незначительных изменениях в нем. Например, представм, что это какой-нибудь Winword, и в нем большой файл, в котором мы поправили запятую, и нажали “сохранить”. ?? весь этот файл, блок за блоком, перезаписался поверх теми же данными, что были (за исключением этой запятой). Не знаю, возможно кто-то подскажет, о чем тут идет речь.</p>
<p>Так или иначе, в результате такой перезаписи, мы будем иметь на дисках <strong>два</strong> файла, из равного набора блоков, один в снэпшоте, а один в собственно файловой системе, ведь WAFL не видит, что там такое произошло с файлом. Попросили из приложения перезаписать стотыщ блоков – вот вам стотыщ свободных блоков, пишите в них, ведь исходный файл в снэпшоте, блоки его нельзя трогать.</p>
<p>Вот для решения такой проблемы и предназначена малоизвестная фича, под названием WAFL File Folding.</p>
<p>Включают ее командой:</p>
<p><code>&gt; options cifs.snapshot_file_folding.enable on</code></p>
<p>и эта команда делает следующее:</p>
<p>В Data ONTAP начинает работать процесс, который физически сравнивает в перезаписываемых файлах блоки данных с соответствующими блоками в наиболее свежем снэпшоте с этого файла. ?? если блоки оказываются идентичными, то просто указывать вместо таких “псевдоизмененных” и “псевдоперезаписанных” блоков, на блоки в крайнем по времени снэпшоте. Это что-то отдаленно напоминает дедупликацию, но там похожий процесс работает только внутри активной файловой системы, между разными в ней файлами, а тут – между пространством активной файловой системы и пространством самого свежего снэпшота.</p>
<p>Теоретически, как и любой процесс экономии пространства, этот процесс дополнительно нагружает процессор и занимает память задачей попарного сравнения блоков. Однако, если этот процес достигает определенного для него лимита использования RAM, он приостанавливается, и ждет ее освобождения, так что в принципе страшного ничего произойти не должно.</p>
<p>Утверждается, что фича эта тихо живет уже довольно давно, полагаю она была добавлена по заказу какого-нибудь Особо Любимого Клиента и его специфической задачи, и не особенно раскручивается для прочих. Данная опция существует в Data ONTAP вплоть до версии 8.1 в 7-Mode.</p>
<p>Так что если в ващем хранилище CIFS есть сходная проблема с перезаписью, то можете попробовать, по идее это должно экономить какое-то количество пространства на дисках, при использовании снэпшотов. Помните, однако, что это займет сколько-то процессора и памяти, так что включив это обязательно проследите за поведением системы какое-то время.</p>
<p><strong>UPD:</strong> из комментариев к &#8220;зеркалу&#8221; данного поста на <a href="https://communities.netapp.com/groups/netapp-ru">https://communities.netapp.com/groups/netapp-ru</a> (если вы там еще не были - сильно рекомендую сходить и ознакомиться, это форум и сообщество по NetApp, созданное мною на официальном сайте NetApp, чтобы было удобнее вести дискуссии и обсуждения, в формате форума, и так далее. Я туда также зеркалю свои посты отсюда).</p>
<p><em>&#8220;Ну именно офисные приложения word и exel и перезаписывают файлы целиком. При открытии файла на редактирование ms офис создает новый временный файл и работаем в нем, а операция сохранения это удаляем старый, копируем новый. То есть файл всегда пишется целиком. А так как на CIFS разделах делать снепшоты очень удобно (в винде встроены механизмы отслеживания версионности файлов и нет необходимости привлекать администраторов чтоб открыть любой файл из предыдущих версий) то начинает быстро &#8220;распухать&#8221; раздел по них.</p>
<p>Поэтому на томах доступных для CIFS где работают с офисными приложениями и снепшоты делаются по сколько раз в день, что затрудняет возможность проведения дедупликации перед ними, данная опция маст хэв :) &#8220;</em></p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="cifs.html" rel="tag">cifs</a>, <a href="folding.html" rel="tag">folding</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>,  <a href="../category/tricks/index.html" title="Просмотреть все записи в рубрике &laquo;tricks&raquo;" rel="category tag">tricks</a>&nbsp;&nbsp;|&nbsp;
					<a href="../1137/trackback.html#comments" title="Комментарий к записи WAFL File Folding">Комментарии (2)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1125">
				<h2 class="posttitle"><a href="../1125/trackback.html" rel="bookmark" title="Permanent Link to Компрессия данных в WAFL: Как это работает?">Компрессия данных в WAFL: Как это работает?</a></h2>
				<div class="postmetadata">5 Март 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Я уже рассказывал о том, что, начиная с ONTAP 8.х, и на 64-bit aggregate, у WAFL есть механизм компрессии хранимых на дисках данных. Механизм онлайн-компрессии сравнительно хорошо знаком пользователям, так как, например, давно поддерживается на NTFS. Однако, по моим наблюдениям, используют его не так часто, боясь его заметного влияния на производительность, и большей нагрузки на процессор сервера. Следует, тем не менее, отметить, что для современных процессоров, производительность которых <em>сильно</em> выросла со времен <em>Stacker</em> и <em>MS DiskDrive</em>, такая дополнительная нагрузка на процессор операций запаковки-распаковки весьма незначительна по абсолютной величине, но при этом значительно уменьшает объемы дискового трафика. Например, если компрессия, вдвое уменьшает “футпринт”, то есть хранимый объем данных, то за счет сравнительно небольшого увеличения (проценты, как правило) нагрузки на процессор, мы можем вдвое увеличить производительность чтения-записи, так как объем данных считываемых и записываемых на диск уменьшается, в нашем случае, вдвое, данные попадают на диск и считываются с него всегда уже сжатыми. </p>
<p>Так что влияние компрессии на производительность может быть совсем не столь однозначно отрицательным.</p>
<p>Но любопытно подробнее разобраться с тем, как реализована компрессия у NetApp. Дело в том, что для файловых систем, хранящих данные в фиксированных блоках-“кластерах” файловой системы, компрессия внутри этих кластеров, зачастую, бесполезна. Данные не могут занимать места менее одного блока (для WAFL – 4KB), то есть экономия места внутри блока никак не может быть использована. Сложность вызывает также работа с большим файлами. Например, в случае “обычной” компрессии файла архиватором типа ZIP, и прочими аналогичными, нам, часто, для того, чтобы извлечь, изменить или записать данные в середину большого файла, приходится распаковать и перепаковать его целиком. Это влечет за собой большую затрату времени и занятой памяти RAM. То что годится для оффлайновых архиваторов – не подходит для онлайн-компрессии.</p>
<p>При создании механизма компрессии инженерам NetApp пришлось решить как эти, так и многие другие проблемы.</p>
<p>Первый интересный с точки зрения “техники процесса” момент организации работы компрессии состоит в том, что алгоритм компрессии работает не с “файлом” целиком, а бъет его на фиксированные сегменты, под названием “Compression Groups”. Каждая Compression Group содержит 8 секторов WAFL, размером 4KB, и имеет размер 32K. </p>
<p><img style="background-image: none; border-bottom: 0px; border-left: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top: 0px; border-right: 0px; padding-top: 0px" title="basics-fig2[1]" border="0" alt="basics-fig2[1]" src="/pics/----WAFL-_96B7/basics-fig21.jpg" width="484" height="169" /></p>
<p>Каждый файл, размещенный на томе, со включенной компрессией, рассматривается алгоритмом компрессии как разбитый на некоторое количество независимо обрабатываемых Compression Groups (CG). Например файл, размером 60KB будет содержать две CG, одну размером 32KB, и одну неполную, размером 28KB. При этом компрессия не применяется к файлам, размерам 8KB и менее.</p>
<p>Каждая CG обрабатывается отдельно, а, при необходимости считывания части файла “из середины”, считывается и распаковывается не весь файл, а только необходимая Compression Group в нем.</p>
<p>Но это еще не все интересное.</p>
<p>Выглядит довольно очевидным решение как-то определять факт невозможности или низкой эффективности сжатия для данных, и данные, которые не жмутся (например JPEG, ZIP, MP3 или AVI) не жать вовсе, сэкономив на этом ресурсы процессора. Ведь в противном случае процессор будет полноценно занят сжатием-разжатием содержимого Compression Groups ради жалких долей процента результата. ??менно так поступили в NetApp. Перед операцией для Compression Group определяется эффективность сжатия, и, если результат получается ниже 25% (менее четверти содержимого группы, то есть менее 8KB, удается высвободить в результате компрессии), то сжатие для данной группы не прозводится вовсе и она записывается неизменной.</p>
<p>Наконец, любопытным решением является разделение операций на онлайновые (inline), то есть производящиеся непосредственно “на лету”, по ходу поступления данных, и постпроцессные (postprocess). Постпроцессный метод уже широко применяется в механизме дедупликации, и позволяет свести к минимуму влияние процесса дедупликации на работу системы и ее производительность.</p>
<p>Несмотря на то, что большинство операций компрессии могут выполнятьcя <em>inlne</em>, в ряде случаев часть операций может оуществляться постпроцессно. Постпроцессная компрессия применяется, в первую очередь, к данным, которые уже лежат на диске, до того, как для содержащего их тома была включена компрессия. Кроме этого, в случае, если инлайновая компрессия не успевает обрабатывать данные, например при большом объеме записей, они также откладываются, записываются несжатыми, и становятся в очередь постпроцессной компрессии.</p>
<p>Постпроцессная компрессия выполняется по тому же расписанию, что и дедупликация, и запускается после выполнения процесса дедупликации для данного тома. Стоит также отметить, что дедупликация и компрессия возможны на одном и том же томе, прекрасно сосуществуют, и не отменяют одна другую. Более того, компрессия после дедупликации вполне возможна. Представьте себе множество виртуальных машин, которые хорошо дедуплицируются, так как содержат одно и то же содержимое, и дедупликация позволит нам хранить не сто виртуальных машин, а одну (и некоторое количество сохраненной “дельты” между этой VM и сотней индивидуальных VM с дедуплицированным нами содержимым) . Но ведь файлы Program Files или пользовательские файлы этого единственного экземпляра, как правило, можно еще и сжать раза в полтора! ?? эта компрессия будет осуществлена над уже дедуплицированным содержимым.</p>
<p>Следует также отметить, что компрессия, так как она осуществляется над фиксированными Compression Groups, не мешает работе дедупликации. Два идентичных и хорошо дедуплицируемых файла, будут разбиты на одинаковое количество Compression Groups, и получившиеся 32KB группы после компрессии останутся по-прежнему идентичными и по прежнему дедуплицируемыми.</p>
<p>Хотя в NetApp предприняли значительные усилия, чтобы повысить эффективность и постараться обеспечить наименьшее влияние на производтельность при работе компрессии, какое-то влияние на производительность (зависящее от множества факторов, как то объемы записей, характер доступа, и так далее) все равно, безусловно, будет иметь место. </p>
<p>Лаборатория NetApp опубликовала следующие оценки производительности для системы FAS6080 (на сегодня это уровень хорошего такого midrange класса FAS3240, пожалуй). Для такой системы были достигнуты показатели работы постпроцессной компрессии на уровне 140MB/s для одного процесса, и 210MB/s максимальной производительности для нескольких процессов одновременно. На загрузке характера файлового сервера, с нагрузкой на процессор не более 50%, задачи inline-компрессии увеличивали нагрузку на менее чем 20% для датасетов, сжимающихся минимум на 50%.</p>
<p>Оценочная эффективность компрессии и дедупликации показывается NetApp для разных наборов данных на следующем графике:</p>
<p><img style="background-image: none; border-bottom: 0px; border-left: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top: 0px; border-right: 0px; padding-top: 0px" title="basics-fig1[2]" border="0" alt="basics-fig1[2]" src="/pics/----WAFL-_96B7/basics-fig12.jpg" width="600" height="420" /></p>
<p>Я бы хотел также упомянуть, что имеющаяся у партнеров NetApp утилита SSET (Space Savings Estimation Tool) в текущей версии позволяет провести оценку эффекивности дедупликации <strong>??</strong> компрессии на реальных пользовательских данных, вычисляя на них результат работы алгоритма NetApp. Эта утилита запускается на реальных данных пользователя, работая в read-only, и, никак не изменяя и не повреждая эти данные, позволяет оценить результат дедупликации и компрессии даже без использования стораджа NetApp, например до его покупки. Эту утилиту можно просить у партнеров, она имеется для Linux и Windows.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="81-ontap.html" rel="tag">8.1 ontap</a>, <a href="compression.html" rel="tag">compression</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<a href="../1125/trackback.html#comments" title="Комментарий к записи Компрессия данных в WAFL: Как это работает?">Комментарии (2)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1119">
				<h2 class="posttitle"><a href="../1119/trackback.html" rel="bookmark" title="Permanent Link to FlexVol и Traditional Volume в NetApp">FlexVol и Traditional Volume в NetApp</a></h2>
				<div class="postmetadata">13 Февраль 2012, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Копаясь в материалах конференции USENIX, в которой исследователи из NetApp всегда принимают весьма активное участие, обнаружил там научную работу с более подробным, чем ранее, описанием того, как работает WAFL и FlexVol.</p>
<p>Работа называется <em>FlexVol: Flexible, Efﬁcient File Volume Virtualization in WAFL </em>и проводит разбор того, как устроен и как работает aggregate и Flexible Volume, а также приводит результаты сравнения производительности на разных нагрузках для Traditional-type и Flexible Volume.</p>
<p>Брать – там: <a href="http://www.usenix.org/event/usenix08/tech/full_papers/edwards/edwards.pdf">http://www.usenix.org/event/usenix08/tech/full_papers/edwards/edwards.pdf</a></p>
<p>Любопытным и интересующимся вопросами “как оно там вообще все устроено” - рекомендую</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="flexvol.html" rel="tag">flexvol</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="usenix.html" rel="tag">usenix</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/review/index.html" title="Просмотреть все записи в рубрике &laquo;review&raquo;" rel="category tag">review</a>&nbsp;&nbsp;|&nbsp;
					<a href="../1119/trackback.html#comments" title="Комментарий к записи FlexVol и Traditional Volume в NetApp">1 комментарий</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1083">
				<h2 class="posttitle"><a href="../1083/trackback.html" rel="bookmark" title="Permanent Link to Как заполненность данными системы хранения влияет на ее производительность?">Как заполненность данными системы хранения влияет на ее производительность?</a></h2>
				<div class="postmetadata">9 Ноябрь 2011, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Сегодня в переводах новый автор, это principal technologist регионального представительства NetApp по Австрали и Новой Зеландии, и директор SNIA ANZ - <a href="http://storagewithoutborders.com/about/www.storagewithoutborders.com" rel="cc:attributionURL"><font color="#0066cc">Richard J Martin</font></a>. Его блог это вообще и в целом довольно отличающееся явление от, увы, распространенного сейчас стиля среди блоггеров “<em>Так как мне не хватает 140 символов моего твиттера, я вынужден написать эти 320 символов в блог, но лучше читайте мой твиттер</em>”, его записи в блог это, порой, настоящие глубокие статьи, которые интересно читать и трудно переводить.</p>
<p>Надеюсь, что он еще не раз появится в моих переводах.</p>
<p>Ричард Мартин, NetApp Australia отвечает на вопрос “как заполненность данными системы хранения влияет на ее производительность?”</p>
<p><h3><a href="http://storagewithoutborders.com/2011/09/10/how-does-capacity-utilisation-affect-performance/">How does capacity utilisation affect performance ?</a></h3>
<p>September 10, 2011 <a href="http://storagewithoutborders.com/author/storagewithoutborders/">storagewithoutborders</a></p>
<p> Несколько дней назад я получил письмо с вопросом &quot;Каковы рекомендации по максимальному уровню использования пространства системы хранения, не вызывающему падения ее производительности?&quot;. С одной стороны такие вопросы раздражают меня, так как чаще всего рождаются из регулярно вбрасываемого FUDa о NetApp, с другой стороны, даже несмотря на то, что правильно спроектированная для стабильного уровня производительности система хранения редко (если такое и вообще возможно) сводится к любой единственной метрике, понимание особенностей использования емкости хранилища и его влияния на производительность, это важный аспект при проектировании вашей системы хранения.</p>
<p>Первое, что я хотел бы сказать, говоря на эту тему, и что хотел бы, чтобы было ясно здесь сказано, это то, что уровень производительности <strong>любой</strong> системы хранения, <strong>любого</strong> производителя, использующей вращающиеся жесткие диски, будет падать пропорционально количеству занятого на них пространства.</p>
<p>Поэтому, отвечая на вопрос, как уровень заполненности системы хранения влияет на ее производительность, мне приходится оговариваться, что &quot;это зависит от ряда факторов&quot;, но в большинстве случаев, когда задают такой вопрос, то спрашивающего он интересует для нагрузки с высоким уровнем операций записи, например VDI, некоторые виды online transaction processing, и системы электронной почты.</p>
<p>Если вы рассматриваете такие варианты нагрузки, то можно смотреть наш старый добрый <a href="http://media.netapp.com/documents/tr-3647.pdf">TR-3647</a> в котором как раз рассматриваются высокие нагрузки со значительными объемами записи, и где говорится:</p>
<blockquote><p>Структура размещения данных WAFL, используемая в Data ONTAP, оптимизирует записи на диск, для улучшения производительности системы и повышения уровня использования полосы пропускания дисков. Оптимизация в WAFL использует небольшой объем свободного или зарезервированного пространства в пределах aggregate. Для высокой нагрузки, связанной с интенсивной записью, мы рекомендуем оставлять незанятым пространство, равное, в среднем, 10% от usable space, для работы этого оптимизационного процесса. Это пространство не только обеспечивает высокопроизводительную запись, но также работает как буфер при неожиданно возникающих потребностях приложения в свободном месте при объемных записях на диск.</p>
</blockquote>
<p>Я видел некоторые бенчмарки, использующие синтетическую нагрузку, где точка перелома графика производительности наблюдалась между 98 и 100% usable емкости, после вычета WAFL reserve, я также видел проблемы производительности, когда люди полностью заполняли все доступное пространство на системе хранения, а затем начинали писать не нее мелкими блоками множество перезаписей данных. Это не является уникальным свойством именно WAFL, в случае любой системы хранения такое ее использование будет довольно плохой идеей, заполнить все пространство на любой структуре данных, а затем пустить на нее объемный random write.</p>
<p>Однако можно смело сказать, что на подавляющем большинстве нагрузок, вы получите на системах NetApp больше &quot;IOPS со шпинделя&quot;, чем у любой аналогично сконфигурированной (и за сходную цену) системы хранения других производителей.</p>
<p>Оставляя в стороне тему FUD, (подробный его разбор требует довольно глубокого понимания внутренней архитектуры ONTAP) при рассмотрении того, как влияет заполнение емкости на производительность на системах хранения NetApp FAS, надо хорошо понимать следующие моменты:</p>
<ol>
<li>Для любого конкретного типа рабочей нагрузки и типа системы хранения вы можете достичь только сравнительно ограниченного числа операций на диск, это число на диск 15K RPM составляет, обычно менее 250.</li>
<li>Производительность системы хранения обычно определяется тем, на сколько дисков может быть распараллелена нагрузка ввода-вывода.</li>
<li>Большинство производителей систем хранения предоставляют для рабочей нагрузки ввода-вывода диски, объединенные в RAID-10, который использует вдвое больше raw-дисков на данный объем usable. При этом NetApp использует RAID-DP, который не требует удваивать количество дисковых шпинделей на заданный объем usable данных.</li>
<li>В большинстве бенчмарков (см. например SPC-1), NetApp использует для тестирования все доступное дисковое пространство, кроме 10% от usable space (в соответствии с написанным в TR-3647) что дает пользователю примерно 60% от емкости raw дисков, при этом достигая того же уровня IOPS/диск, которое другие производители получают при уровне usable в 30% от raw. Таким образом, равную производительность из расчет на жесткий диск мы обеспечиваем при на 10% большем уровне usable пространства, чем другие производители могут теоретически достичь при использовании RAID-10.</li>
</ol>
<p>В итоге, даже без использования дедупликации и thin provisioning, или чего-то подобного, вы можете хранить вдвое больше данных на системе хранения NetApp FAS, обеспечивая тот же уровень производительности, как и большинство конкурирующих решений с RAID-10.</p>
<p>Хотя все это действительно правда, следует отметить, что тут есть и один недостаток. Хотя величина IOPS/Spindle более-менее та же, величина &quot;плотности IOPS&quot; (IOPS density) измеренная в IOPS/GB для результатов NetApp SPC-1 составляет примерно половину от решений конкурентов, (те же IOPS , 2x данных = вдвое меньше плотность). Хотя это на самом деле и сложнее сделать, за счет более низкого соотношения cache/data, если у вас есть приложение, которое требует очень высокой плотности IOPS/GB (например некоторые инфраструктуры VDI), тогда вы можете не использовать всю имеющуюся у вас дополнительную емкость под эту нагрузку ввода-вывода. Все это дает вам, в результате, возможность выбора из трех вариантов.</p>
<ol>
<li>Не использовать это дополнительное место, оставив его незанятым на aggregate, позволить работать на нем оптимизации записей и получить лучшую производительность.</li>
<li>??спользовать дополнительное место, например для данных некритичных к производительности, таким как хранение снэпшотов, или зеркальная реплика данных, или архивы, и так далее, и установить этой нагрузке пониженный приоритет с помощью FlexShare.</li>
<li>Установить карту Flash Cache, которая удвоит эффективные показатели IOPS (зависит от вида нагрузки, конечно) на физический диск, что обойдется дешевле, и сэкономит ресурсы, чем удвоение количества физических дисков.</li>
</ol>
<p>Если вы поступаете иначе, то вы можете получить ситуацию, когда наша высокая эффективность использования пространства позволяет пользователю запустить слишком большую нагрузку по вводу-выводу на недостаточном количестве физических жестких дисков, и, к сожалению, снова снова порождает пресловутый и бесконечно гуляющий FUD о &quot;Netapp Capacity / Performance&quot;. </p>
<p>Он некорректен прежде всего потому, что причина тут не в каких-то тонкостях Data ONTAP или WAFL, а в том, что на систему, сайзинг которой был проведен для рабочей нагрузки X, помещают 3X данных, так как &quot;на дисках еще есть место&quot;, и весь ввод-вывод этих 2-3-кратного объема данных наваливается на дисковые шпиндели, запланированные под совсем другой уровень нагрузки и объемов.</p>
<p>Для того, чтобы сделать счастливыми, и, что немаловажно, поддерживать это состояние в пользователях вашей системы хранения, вам, как администратору, нужно уметь управлять не только доступной вам емкостью, но и доступной производительностью системы хранения. Чаще всего у вас будет исчерпываться одно раньше, чем другое, и работа эффективной IT инфраструктры означает умение балансировать рабочую нагрузку между этими двумя ресурсами. В первую очередь это означает, что вы потратили определенное время измеряя и мониторя емкость и производительность вашей системы. Кроме этого вам следует настроить вашу систему так чтобы иметь возможность мигрировать и ребалансировать нагрузку между ресурсными пулами, или же иметь возможность легко добавлять дополнительную производительность для имеющейся нагрузки не прерывая нормальной работы системы, что может быть осуществлено с помощью таких технологий, как Storage DRS в vSphere 5, или Data Motion и Virtual Storage Tiering в Data ONTAP.</p>
<p>Когда вы наблюдаете за параметрами вашей системы хранения, вы можете своевременно принять меры, до того, как какие-либо проблемы проявятся. У NetApp есть множество великолепных инструментов по мониторингу производительности всей системы хранения. Performance Advisor дает вам визуализированные и настраиваемые алерты и пороги их срабатывания для встроенных метрик производительности, доступных в каждой системе хранения FAS, а OnCommand Insight Balance предоставляет углубленный отчет и упреждающий анализ для всей вашей виртуализованной инфраструктуры, включающей, в том числе, и стороннее, не-NetApp, оборудование.</p>
<p>Вне зависимости, используете ли вы инструменты NetApp, или какие-то другие, важно то, что вы их используете, и потратили немного своего времени на то, чтобы найти подходящие метрики оценки, и решение, что нужно делать, если превышен тот или иной верхний порог. Если вы не уверены в правильности выбора метрик для вашего оборудования - спросите меня, или даже лучше опубликуйте вопрос в <a href="http://communities.netapp.com/index.jspa">комьюнити NetApp</a>, которое имеет куда более высокую посещаемость, чем этот блог.</p>
<p>Хотя я понимаю весь соблазн вернуться к старой практике, привычной для &quot;классических&quot; систем хранения, когда для системы хранения почти нет шансов превысить ее возможности по IOPS, прежде чем она исчерпает свои возможности по емкости, это почти всегда невероятно расточительно, и ведет, по моему опыту, к уровню использования емкости около 20% и менее, и приводит к экономически неоправданной цене/GB для таких “Tier-1″ хранилищ. Возможно еще настанут &quot;сытные годы&quot;, когда администраторы будут снова иметь роскошь не обращать внимания на цену решения, или, быть может, вы окажетесь в такой редкой отрасли, где &quot;цена не имеет значения&quot;, однако для остальных нынешние времена - времена начистить и привести в готовность свои навыки мониторинга, настройки и оптимизации. Сегодня спрос есть на умение делать больше с меньшими затратами, и надо учиться этому.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="capacity.html" rel="tag">capacity</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="performance/index.html" rel="tag">performance</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/translations/index.html" title="Просмотреть все записи в рубрике &laquo;переводы&raquo;" rel="category tag">переводы</a>&nbsp;&nbsp;|&nbsp;
					<a href="../1083/trackback.html#comments" title="Комментарий к записи Как заполненность данными системы хранения влияет на ее производительность?">Комментарии (5)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-1077">
				<h2 class="posttitle"><a href="../1077.html" rel="bookmark" title="Permanent Link to Flash Cache/PAM не кэширует WAFL-compressed данные">Flash Cache/PAM не кэширует WAFL-compressed данные</a></h2>
				<div class="postmetadata">31 Октябрь 2011, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Хотел бы обратить внимание тех, кто планирует использование новой возможности на системах хранения NetApp – <em>WAFL online compression</em>, то есть сжатия данных “на лету”, для хранения их на диске в сжатом виде. В настоящий момент блоки, которые были компрессированы таким образом, не кэшируются в Flash Cache / PAM.</p>
<p>Как вы знаете, у NetApp есть сейчас две основных технологии снижения storage footprint, то есть объемов хранения, занимающих физическое дисковое пространство, это давно существующая и хорошо себя зарекомендовавшая во многих случаях <em>дедупликация</em>, и появившаяся сравнительно недавно <em>онлайн-компрессия</em>. Две эти технологии существуют и работают независимо друг от друга, и даже дополняют друг друга. Каждая из них имеет свои предпочтительные области применения. Например, дедупликация хорошо работает для сред виртуализации, где ее эффективность (величина экономии после ее применения) может достигать 70-85% от первоначально занятого на дисках, но в рядя других применений, например для баз данных, ее эффективность (по разным причинам, на которых мы не будем сейчас подробно останавливаться) значительно ниже, часто не более 10-20%. </p>
<p>Напротив, компрессия довольно неплохо уменьшает объем хранения для пользовательских файлов и баз данных (35-50%). Она также сравнительно неплохо работает даже и на <em>уже дедуплицированных данных</em>, что может еще повысить результаты экономии.</p>
<p>Сравнительно неплохая эффективность компрессии на датасетах типа баз, например, может натолкнуть вас на мысль использовать компрессию для ваших баз данных, на системах, которые часто используют Flash Cache для повышения производительности работы. Но тут вот стоит принять во внимание момент, который я вынес в заголовок заметки: Блоки, которые располагаются на томе, с включенной компрессией, и подверглись компрессии, не кэшируются во Flash Cache.</p>
<p>Это диаметральным образом противоположно ситуации с дедупликацией, так как дедуплицированные блоки, напротив, попадают в <em>dedupe-aware</em> кэш, который знает о их дедуплицированности, и умеет ее использовать (например блок, на который на диске имеется десять ссылкок из десяти разных VMDK, будет считан и находиться в кэше не в 10, как в традиционной форме кэширования, а всего в одном экземпляре, что, очевидно, увеличивает эффективную емкость кэша). </p>
<p>Если у вас система с Flash Cache, и вы одновременно собираетесь использовать компрессию для данных – то будьте внимательны. Компрессированные тома в системе с Flash Cache могут иметь значительно отличающуюся от некомпрессированных производительность, за счет того, что с некомпрессированными томами работа будет идти через Flash Cache, а с компрессированными – нет. Эта разница, не слишком заметная для систем без Flash Cache, за счет такого поведения для систем с Flash Cache, может быть неприятным сюрпризом.</p>
<p>Эта особенность работы компрессии описана в новом <strong>TR-3958 Compression and Deduplication for DataONTAP 8.1 operating in 7-Mode</strong> на странице 22: </p>
<p>7.6 PAM AND FLASH CACHE CARDS </p>
<p>In environments with high amounts of shared blocks that are read repeatedly, the PAM or Flash Cache card can significantly reduce the number of disk reads, thus improving the read performance. <font color="#ff0000">The PAM or Flash Cache card does not increase performance of the compression engine or of reading compressed data</font>. The amount of performance improvement with the PAM or Flash Cache card depends on the amount of shared blocks, the access rate, the active dataset size, and the data layout. The PAM or Flash Cache card has provided significant performance improvements in VMware® VDI environments. These advantages are further enhanced when combined with shared block technologies, such as NetApp deduplication or NetApp FlexClone® technology.</p>
<p>Так что обратите внимание на этот момент, и не применять компрессию для томов, производительность которых для вашей задачи критична, и которые вы планируете ускорить с помощью Flash Cache</p>
<p>UPD: Попросили уточнить. По-прежнему кэшируются во Flash Cache НЕсжатые блоки на сжатом томе (например, если эти блоки были исключены из процесса сжатия в результате плохого compression rate на этапе estimate для этих блоков). Но, так как нет механизма управлять тем, какие именно блоки или файлы будут компрессированы на томе, а какие - нет (компрессия назначается на том целиком), то это, в общем, довольно <i>теоретическая</i> поправка, не меняющая моей итоговой рекомендации.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="compression.html" rel="tag">compression</a>, <a href="deduplication/index.html" rel="tag">deduplication</a>, <a href="flash-cache.html" rel="tag">flash cache</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<span>Comments Off</span>									 </div>
			</div>
	
						
			<div class="post" id="post-927">
				<h2 class="posttitle"><a href="../927/trackback.html" rel="bookmark" title="Permanent Link to Оптимизация на Large Sequental Read">Оптимизация на Large Sequental Read</a></h2>
				<div class="postmetadata">30 Май 2011, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Large Sequental Read, или чтение последовательными большими блоками, это один из распространенных паттернов доступа к данным. Например, с таким характером доступа работают такие задачи, как Decision Suport System (DSS), системы Business Intelligence (BI), а также многие задачи резервного копирования (full backup, например).</p>
<p>Вследствие характера работы WAFL, такой паттерн доступа может быть проблемным для систем хранения NetApp, поэтому, если ваши задачи часто используют Large Sequental Read, то стоит позаботиться о некоторых методах оптимизации. Я уже писал, что ситуацию с производительностью на последовательном чтении улучшает регулярное выполнение операций реаллокации (они выполняются по расписанию, или при превышении порогового уровня non-contiguous blocks placement, не обязательно гонять его вручную). Также в блоге специалиста NetApp по нагрузочному тестированию и производительности, <a href="http://blogs.netapp.com/pseudo_benchmark">Wei Liu</a>, я приметил еще одну оптимизационную фишечку.</p>
<p>В системах Data ONTAP версии 7.3.2 и новее имеется опция <code>wafl_max_write_alloc_blocks</code>, по умолчанию она установлена в 64. Если у вас работа с данными осуществляется преимущественно большими блоками, имеет смысл увеличить его значение до 256. Этот параметр, наскольно я могу судить из его названия, управляет размером экстента записи данных. О влиянии и смысле этого элемента дисковой структуры я недавно писал в посте про &#8220;фрагмнтацию&#8221;. Для версий до 7.3.2 этот параметр нужно было установить в файле /etc/rc в виде строки:     <br /><code>setflag wafl_max_write_alloc_blocks 256</code></p>
<p>Эта опция оптимизирует работу WAFL при работе большими последовательными блоками. Я могу ошибаться, но, исходя из моего понимания процессов за которые она отвечает, сказываться она будет не просто при включении, а при включении и последующей записи на том, или после реаллокации блоков на томе (вы помните, надеюсь, что WAFL не перезаписывает однажды занятые блоки, поэтому структура для уже записанных данных, на момент включения опции, никак не изменится). Поэтому, возможно, заметить эффект от ее использования получится не сразу же.</p>
<p>Опция была подсмотрена в документе: <a href="http://media.netapp.com/documents/tr-3760.pdf">TR-3760: Building a Scalable Data Warehouse Solution</a>, кстати любопытного и самого по себе чтива.</p>
<p>Отдельно обращу ваше внимание, что не стоит сразу бросаться “тюнить” систему, так как данная опция, вероятнее всего, положительно влияет только на производительность large sequental read, и может не сказаться, или сказаться отрицательно на всех других. Но если у вас DSS-like база, то, может быть, можно и попробовать.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="netapp/index.html" rel="tag">netapp</a>, <a href="optimization.html" rel="tag">optimization</a>, <a href="sequental-read.html" rel="tag">sequental read</a>, <a href="tips.html" rel="tag">tips</a>, <a href="tricks/index.html" rel="tag">tricks</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/tricks/index.html" title="Просмотреть все записи в рубрике &laquo;tricks&raquo;" rel="category tag">tricks</a>&nbsp;&nbsp;|&nbsp;
					<a href="../927/trackback.html#respond" title="Комментарий к записи Оптимизация на Large Sequental Read">Комментарий</a>									 </div>
			</div>
	
						
			<div class="post" id="post-881">
				<h2 class="posttitle"><a href="../881/trackback.html" rel="bookmark" title="Permanent Link to Откуда вообще берется фрагментация?">Откуда вообще берется фрагментация?</a></h2>
				<div class="postmetadata">21 Апрель 2011, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>Так что же там на самом деле происходит с фрагментацией на NetApp?</p>
<p>Давайте, для начала, разберемся с основами. Я в этом блоге уже не раз писал о проблеме фрагментации, и желающих сошлю в более ранние посты, например <a href="../221/trackback.html">сюда</a> и <a href="../225/trackback.html">сюда</a>.</p>
<p>К сожалению тема фрагментации данных на WAFL до сих пор остается в некотором роде <a href="http://dic.academic.ru/dic.nsf/enc3p/333174">эзотерическим</a> знанием. Связано это, в первую очередь с тем, как мне представляется, что рассказ о фрагментации и необходимом противодействии ему, затрагивает ряд чувствительных особенностей функционирования WAFL, деталях, которые NetApp, по разным причинам (совсем не обязательно злонамеренным), разглашать пока не хочет.</p>
<p>Поэтому официальная позиция состоит в рекомендации, в случае, если влияние фрагментации в вашем конкретном случае, проявляется негативно (она, кстати, может и не проявляться), то включать wafl reallocate ( <code>reallocate on / reallocate start [/vol/volname]</code>) и спать счастливо.</p>
<p>Вообще же FUD вокруг <em>non-contiguous wafl blocks allocation</em> построен (впрочем, как и почти любой FUD) вокруг плохого представления технических деталей процесса и иногда чистосердечного, а чаще злонамеренного “непонимания” этих деталей. Давайте, для начала, разберем как же записываются данные в WAFL, по крайней мере на том уровне, на котором нам этот процесс показывает NetApp.</p>
<p>Но начать придется издалека.</p>
<p>   <a href="../881/trackback.html#more-881" class="more-link"><small>Continue reading &#8216;Откуда вообще берется фрагментация?&#8217; &raquo;</small></a></p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="fragmentation.html" rel="tag">fragmentation</a>, <a href="fud/index.html" rel="tag">fud</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<a href="../881/trackback.html#comments" title="Комментарий к записи Откуда вообще берется фрагментация?">Комментарии (12)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-874">
				<h2 class="posttitle"><a href="../874/trackback.html" rel="bookmark" title="Permanent Link to О &ldquo;дефрагментации&rdquo;">О &ldquo;дефрагментации&rdquo;</a></h2>
				<div class="postmetadata">11 Апрель 2011, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>“Усилиями” наших конкурентов все нынешние и будущие пользователи NetApp проинформированы, что “у этих netapp”, дескать, “огромная фрагментация”. Как обычно в области FUD (<a href="http://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt">Fear, uncertainty and doubt</a>), строится это все вокруг плохого понимания предмета, слабой технической подготовки “обрабатываемого”, а порой и откровенной манипуляции фактами. Отсутствие же ясного понимания темы, к сожалению, вызывает к жизни довольно много “техномистицизма” и накрученных вокруг догадок и слухов, которые, как и положено слухам, кормят и размножают сами себя.</p>
<p>В четверг я опубликую заметку о “теории” возникновения фрагментации на дисках вообще, интересующиеся отсылаются в нее. А пока хотел лишь обратить внимание читателей на прискорбную тенденцию, с которой встречаюсь уже не впервой.</p>
<p>Пользователи NetApp, которые не особенно копенгаген в технических деталях, но которым надули в уши про “ужасную фрагментацию на NetApp”, считают, что раз что-то на NetApp, значит это что-то надо “дефрагментировать”, и чем чаще, тем лучше. Причем под “дефрагментировать” обычно понимается виндовый defrag.exe, или же еще какой Diskeeper.&#160; <br />Прискорбное заблуждение.</p>
<p>Еще более прискорбным оно становится, если дело происходит на диске виртуальной машины.</p>
<p>Если вы внимательно прочли наш <a href="http://www.netwell.ru/production/techbiblioteka.php">переводной Best Practices</a> по работе с <a href="../789/trackback.html">VMware</a> или <a href="../570/trackback.html">Hyper-V</a>,то должны были обратить внимание на строгое указание не использовать дефрагментатор OS на дисках, расположенных на системе хранения NetApp, будь то iSCSI/FC LUN, смонтированный на сервер, или же VHD/vmdk виртуальной машины.</p>
<p>Дело в том, что дефрагментатор в OS, это программа, которая ничего не знает о той, часто непростой структуре, что лежит под тем, что она считает “обычным жестким диском”. Она видит нечто (LUN), которое представляется ей обычным жестким диском, с секторами, головками и цилиндрами, но в случае LUN все это не имеет настоящего физического смысла. Под таким “псевдо-диском” могут лежать структуры RAID, или те или иные структуры организации его физических блоков (в случае NetApp – WAFL, в случае других систем, других вендоров – другие структуры) . На этом уровне работает непростая&#160; дорогостоящая логика оптимизации доступа в больших системах хранения, которая знает как, и умеет оптимизировать доступ к своим данным. ?? вмешательство в эту логику примитивной “дефрагментации” на уровне OS не только бессмысленно, но и нежелательно. ?? уж точно никак с помощью defrag.exe не справиться с проблемой “фрагментации данных на NetApp”, ситуацию можно только ухудшить.</p>
<p>В случае конкретно NetApp, выполнение “дефрагментации” на уровне клиентской OS или виртуальной машины:</p>
<ol>
<li>Резко увеличивает объемы, занимаемые снэпшотами, так как пространство диска на NetApp со взятым снэпшотом занимает только изменения (записи), сделанные на нем после создания снэпшота, а “дефрагментация” при работе перезаписывает почти весь диск, то вы обнаружите, что снэпшот после такой “дефрагментации” практически удвоит занимаемое вашим томом на дисках место </li>
<li>Портит оптимизацию доступа на уровне системы хранения, так как то, что, по мнению дефрагментатора, лежит рядом и последовательно, физически, на уровне системы хранения, и собственно физических дисков, может лежать совсем НЕ рядом и НЕ последовательно, и наоборот. </li>
<li>Замусоривает кэш и загружает канал ввода-вывода бессмысленными операциями. </li>
</ol>
<p>?? в итоге – не приводит ни к чему, так как “фрагментацию” на уровне самого NetApp так не исправить, скорее наоборот, многочисленными перезаписями ее можно только ухудшить.</p>
<p>Если вы все равно не осилили все написанное выше, то просто следуйте простым советам:</p>
<ul>
<li><strong>Не используйте дефрагментацию в OS</strong> (defrag.exe, Diskeeper, Norton Defrag, etc.) для данных, расположенных на системе хранения NetApp. В том числе отключите автоматическую оптимизацию (Boot Time Optimization) и фоновую дефрагментацию дисков в OS Windows. </li>
<li>Не обращайте внимания на величины “фрагментации”, указываемые самой OS для LUN-ов и дисков виртуальных машин, размещенных на NetApp. </li>
<li>Для минимизации эффекта фрагментации записи непосредственно на дисках системы хранения NetApp используйте включение по расписанию встроенный в Data ONTAP реаллокатор (reallocate on / reallocate start [/vol/volname]). </li>
</ul>
<p>&#160;</p>
<p>&#160;</p>
<p><font color="#cccccc">ЗЫ. Вообще писалось все это смешно. Я сел а ноут, написал заголовок: “Несколько слов о дефрагментации”, и начал писать. Спустя два часа и примерно к конце третьего килобайта написанного я остановился, хмыкнул, посмотрел на заголовок… ?? удалил из него “Несколько слов”, так как на “несколько слов” получающийся трактат никак не тянул. :)      <br />В конце концов я решил разделить тему. В первую часть вынести все же “несколько слов”, те, которые и намеревался написать, а в четверговый пост пустить всю остальную “теорию большого взрыва”, которую, возможно, кому-то захочется прочитать, чтобы разобраться в деталях темы.</font></p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="fragmentation.html" rel="tag">fragmentation</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="reallocate.html" rel="tag">reallocate</a>, <a href="wafl/index.html" rel="tag">wafl</a><br />					Раздел: <a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;" rel="category tag">techtalk</a>&nbsp;&nbsp;|&nbsp;
					<a href="../874/trackback.html#comments" title="Комментарий к записи О &ldquo;дефрагментации&rdquo;">Комментарии (3)</a>									 </div>
			</div>
	
						
			<div class="post" id="post-641">
				<h2 class="posttitle"><a href="../641/trackback.html" rel="bookmark" title="Permanent Link to Компрессия на WAFL?">Компрессия на WAFL?</a></h2>
				<div class="postmetadata">22 Июль 2010, 8:00 <!-- от  --></div>
				<div class="postentry">
					<p>В <a href="http://blogs.netapp.com/virtualstorageguy/2010/07/data-deduplication-and-data-compression-in-data-ontap.html">блоге Vaughan Stewart</a> была найдена интресная картинка:</p>
<p><a href="/pics//compression.jpg"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="compression" border="0" alt="compression" src="/pics//compression-thumb.jpg" width="564" height="480" /></a> </p>
<p>Да, это то что вы подумали. Начиная с Data ONTAP 7.3.3 и 8.0.1 на WAFL теперь работает компрессия (лицензия бесплатна, как iSCSI, или дедупликация, например), причем использование компрессии не отменяет и не заменяет, и может использоваться как совместно с дедупликацией, так и по отдельности. Это такая же знакомая и привычная онлайн-компрессия как на NTFS, например.</p>
<p>Компрессия пригодится в случаях, когда на диске лежат различные по содержимому данные, но не слишком дублирующиеся внутри на уровне 4KB-блоков WAFL. Тем не менее содержимое этих файлов вполне может сжиматься классическими LZ-алгоритмами. Например у меня на ноутбуке папка Program Files диска C: сжата почти на 30% от ее, примерно 2GB, объема.   <br />Хороший пример – homedir различных пользователей организации. Хотя в хоумдирах иногда и попадаются идентичные документы и файлы у разных людей, в основном же, как показывает практика, большая часть содержимого хоумдиров достаточно уникальна, и не слишком эффективно дедуплицируется. Однако вполне поддается традиционному zip-like сжатию с неплохими показателями.</p>
<p>Для 7.3.3 компрессия идет как PVR, то есть доступна по запросу, но запланирована как стандартная опция в 8.0.1, которая выйдет этой осенью.</p>
				</div>
		
				<div class="postmetadata">
					Метки: <a href="compression.html" rel="tag">compression</a>, <a href="netapp/index.html" rel="tag">netapp</a>, <a href="wafl/index.html" rel="tag">wafl</a>, <a href="news/index.html" rel="tag">новости</a><br />					Раздел: <a href="../category/news/index.html" title="Просмотреть все записи в рубрике &laquo;новости&raquo;" rel="category tag">новости</a>&nbsp;&nbsp;|&nbsp;
					<a href="../641/trackback.html#comments" title="Комментарий к записи Компрессия на WAFL?">Комментарии (4)</a>									 </div>
			</div>
	
		
		<div class="navigation">
			<div class="alignleft"><a href="wafl/page/2.html">&laquo; Previous Entries</a></div>
			<div class="alignright"></div>
		</div>
		
	
	</div>
	<div id="sidebar">
		<ul>
			
			
			<!-- Author information is disabled per default. Uncomment and fill in your details if you want to use it.
			<li><h2>Автор</h2>
			<p>A little something about you, the author. Nothing lengthy, just an overview.</p>
			</li>
			-->

			<li class="pagenav"><h2>Страницы</h2><ul><li class="page_item page-item-153"><a href="../../about/trackback.html" title="about">about</a></li>
<li class="page_item page-item-215"><a href="../../distributory-v-rossii/trackback.html" title="Дистрибуторы в России">Дистрибуторы в России</a></li>
<li class="page_item page-item-1327"><a href="../../disti-ua/trackback.html" title="Дистрибуторы в Украине">Дистрибуторы в Украине</a></li>
</ul></li>
			<li><h2>Рубрики</h2>
				<ul>
					<li class="cat-item cat-item-89"><a href="../category/commands/index.html" title="Просмотреть все записи в рубрике &laquo;commands&raquo;">commands</a>
</li>
	<li class="cat-item cat-item-37"><a href="../category/howto/index.html" title="Просмотреть все записи в рубрике &laquo;howto&raquo;">howto</a>
</li>
	<li class="cat-item cat-item-52"><a href="../category/justread/index.html" title="Просмотреть все записи в рубрике &laquo;justread&raquo;">justread</a>
</li>
	<li class="cat-item cat-item-51"><a href="../category/review/index.html" title="Просмотреть все записи в рубрике &laquo;review&raquo;">review</a>
</li>
	<li class="cat-item cat-item-3"><a href="../category/techtalk/index.html" title="Просмотреть все записи в рубрике &laquo;techtalk&raquo;">techtalk</a>
</li>
	<li class="cat-item cat-item-71"><a href="../category/tricks/index.html" title="Просмотреть все записи в рубрике &laquo;tricks&raquo;">tricks</a>
</li>
	<li class="cat-item cat-item-95"><a href="../category/utilities/index.html" title="Просмотреть все записи в рубрике &laquo;utilities&raquo;">utilities</a>
</li>
	<li class="cat-item cat-item-44"><a href="../category/whoisho/index.html" title="Просмотреть все записи в рубрике &laquo;whoisho&raquo;">whoisho</a>
</li>
	<li class="cat-item cat-item-1"><a href="../category/news/index.html" title="Просмотреть все записи в рубрике &laquo;новости&raquo;">новости</a>
</li>
	<li class="cat-item cat-item-387"><a href="../category/opros.html" title="Просмотреть все записи в рубрике &laquo;опрос&raquo;">опрос</a>
</li>
	<li class="cat-item cat-item-8"><a href="../category/translations/index.html" title="Просмотреть все записи в рубрике &laquo;переводы&raquo;">переводы</a>
</li>
	<li class="cat-item cat-item-40"><a href="../category/citaty/index.html" title="Просмотреть все записи в рубрике &laquo;цитаты&raquo;">цитаты</a>
</li>
				</ul>
			</li>

			<li><h2>Архивы</h2>
				<ul>
					<li><a href='../date/2018/01.html' title='Январь 2018'>Январь 2018</a></li>
	<li><a href='../date/2015/10.html' title='Октябрь 2015'>Октябрь 2015</a></li>
	<li><a href='../date/2015/04.html' title='Апрель 2015'>Апрель 2015</a></li>
	<li><a href='../date/2015/03.html' title='Март 2015'>Март 2015</a></li>
	<li><a href='../date/2015/01.html' title='Январь 2015'>Январь 2015</a></li>
	<li><a href='../date/2014/12.html' title='Декабрь 2014'>Декабрь 2014</a></li>
	<li><a href='../date/2014/11.html' title='Ноябрь 2014'>Ноябрь 2014</a></li>
	<li><a href='../date/2014/10.html' title='Октябрь 2014'>Октябрь 2014</a></li>
	<li><a href='../date/2014/09.html' title='Сентябрь 2014'>Сентябрь 2014</a></li>
	<li><a href='../date/2014/08.html' title='Август 2014'>Август 2014</a></li>
	<li><a href='../date/2014/07.html' title='Июль 2014'>Июль 2014</a></li>
	<li><a href='../date/2014/06.html' title='Июнь 2014'>Июнь 2014</a></li>
	<li><a href='../date/2014/05.html' title='Май 2014'>Май 2014</a></li>
	<li><a href='../date/2014/04.html' title='Апрель 2014'>Апрель 2014</a></li>
	<li><a href='../date/2014/03.html' title='Март 2014'>Март 2014</a></li>
	<li><a href='../date/2014/02.html' title='Февраль 2014'>Февраль 2014</a></li>
	<li><a href='../date/2014/01.html' title='Январь 2014'>Январь 2014</a></li>
	<li><a href='../date/2013/12.html' title='Декабрь 2013'>Декабрь 2013</a></li>
	<li><a href='../date/2013/11.html' title='Ноябрь 2013'>Ноябрь 2013</a></li>
	<li><a href='../date/2013/10.html' title='Октябрь 2013'>Октябрь 2013</a></li>
	<li><a href='../date/2013/09.html' title='Сентябрь 2013'>Сентябрь 2013</a></li>
	<li><a href='../date/2013/08.html' title='Август 2013'>Август 2013</a></li>
	<li><a href='../date/2013/07.html' title='Июль 2013'>Июль 2013</a></li>
	<li><a href='../date/2013/06.html' title='Июнь 2013'>Июнь 2013</a></li>
	<li><a href='../date/2013/05.html' title='Май 2013'>Май 2013</a></li>
	<li><a href='../date/2013/04.html' title='Апрель 2013'>Апрель 2013</a></li>
	<li><a href='../date/2013/03.html' title='Март 2013'>Март 2013</a></li>
	<li><a href='../date/2013/02.html' title='Февраль 2013'>Февраль 2013</a></li>
	<li><a href='../date/2013/01.html' title='Январь 2013'>Январь 2013</a></li>
	<li><a href='../date/2012/12.html' title='Декабрь 2012'>Декабрь 2012</a></li>
	<li><a href='../date/2012/11.html' title='Ноябрь 2012'>Ноябрь 2012</a></li>
	<li><a href='../date/2012/10.html' title='Октябрь 2012'>Октябрь 2012</a></li>
	<li><a href='../date/2012/09.html' title='Сентябрь 2012'>Сентябрь 2012</a></li>
	<li><a href='../date/2012/08.html' title='Август 2012'>Август 2012</a></li>
	<li><a href='../date/2012/07.html' title='Июль 2012'>Июль 2012</a></li>
	<li><a href='../date/2012/06.html' title='Июнь 2012'>Июнь 2012</a></li>
	<li><a href='../date/2012/05.html' title='Май 2012'>Май 2012</a></li>
	<li><a href='../date/2012/04.html' title='Апрель 2012'>Апрель 2012</a></li>
	<li><a href='../date/2012/03.html' title='Март 2012'>Март 2012</a></li>
	<li><a href='../date/2012/02.html' title='Февраль 2012'>Февраль 2012</a></li>
	<li><a href='../date/2012/01.html' title='Январь 2012'>Январь 2012</a></li>
	<li><a href='../date/2011/12.html' title='Декабрь 2011'>Декабрь 2011</a></li>
	<li><a href='../date/2011/11.html' title='Ноябрь 2011'>Ноябрь 2011</a></li>
	<li><a href='../date/2011/10/index.html' title='Октябрь 2011'>Октябрь 2011</a></li>
	<li><a href='../date/2011/09/index.html' title='Сентябрь 2011'>Сентябрь 2011</a></li>
	<li><a href='../date/2011/08.html' title='Август 2011'>Август 2011</a></li>
	<li><a href='../date/2011/07/index.html' title='Июль 2011'>Июль 2011</a></li>
	<li><a href='../date/2011/06/index.html' title='Июнь 2011'>Июнь 2011</a></li>
	<li><a href='../date/2011/05/index.html' title='Май 2011'>Май 2011</a></li>
	<li><a href='../date/2011/04/index.html' title='Апрель 2011'>Апрель 2011</a></li>
	<li><a href='../date/2011/03/index.html' title='Март 2011'>Март 2011</a></li>
	<li><a href='../date/2011/02.html' title='Февраль 2011'>Февраль 2011</a></li>
	<li><a href='../date/2011/01.html' title='Январь 2011'>Январь 2011</a></li>
	<li><a href='../date/2010/12.html' title='Декабрь 2010'>Декабрь 2010</a></li>
	<li><a href='../date/2010/11/index.html' title='Ноябрь 2010'>Ноябрь 2010</a></li>
	<li><a href='../date/2010/10/index.html' title='Октябрь 2010'>Октябрь 2010</a></li>
	<li><a href='../date/2010/09/index.html' title='Сентябрь 2010'>Сентябрь 2010</a></li>
	<li><a href='../date/2010/08.html' title='Август 2010'>Август 2010</a></li>
	<li><a href='../date/2010/07/index.html' title='Июль 2010'>Июль 2010</a></li>
	<li><a href='../date/2010/06.html' title='Июнь 2010'>Июнь 2010</a></li>
	<li><a href='../date/2010/05.html' title='Май 2010'>Май 2010</a></li>
	<li><a href='../date/2010/04/index.html' title='Апрель 2010'>Апрель 2010</a></li>
	<li><a href='../date/2010/03/index.html' title='Март 2010'>Март 2010</a></li>
	<li><a href='../date/2010/02.html' title='Февраль 2010'>Февраль 2010</a></li>
	<li><a href='../date/2010/01.html' title='Январь 2010'>Январь 2010</a></li>
	<li><a href='../date/2009/12/index.html' title='Декабрь 2009'>Декабрь 2009</a></li>
	<li><a href='../date/2009/11/index.html' title='Ноябрь 2009'>Ноябрь 2009</a></li>
	<li><a href='../date/2009/10.html' title='Октябрь 2009'>Октябрь 2009</a></li>
	<li><a href='../date/2009/09.html' title='Сентябрь 2009'>Сентябрь 2009</a></li>
	<li><a href='../date/2009/08/index.html' title='Август 2009'>Август 2009</a></li>
	<li><a href='../date/2009/07/index.html' title='Июль 2009'>Июль 2009</a></li>
	<li><a href='../date/2009/06.html' title='Июнь 2009'>Июнь 2009</a></li>
	<li><a href='../date/2009/05.html' title='Май 2009'>Май 2009</a></li>
	<li><a href='../date/2009/04.html' title='Апрель 2009'>Апрель 2009</a></li>
	<li><a href='../date/2009/03.html' title='Март 2009'>Март 2009</a></li>
	<li><a href='../date/2009/02.html' title='Февраль 2009'>Февраль 2009</a></li>
	<li><a href='../date/2009/01.html' title='Январь 2009'>Январь 2009</a></li>
	<li><a href='../date/2008/12.html' title='Декабрь 2008'>Декабрь 2008</a></li>
	<li><a href='../date/2008/11.html' title='Ноябрь 2008'>Ноябрь 2008</a></li>
	<li><a href='../date/2008/10.html' title='Октябрь 2008'>Октябрь 2008</a></li>
	<li><a href='../date/2008/09.html' title='Сентябрь 2008'>Сентябрь 2008</a></li>
	<li><a href='../date/2008/08.html' title='Август 2008'>Август 2008</a></li>
	<li><a href='../date/2008/03.html' title='Март 2008'>Март 2008</a></li>
	<li><a href='../date/2008/02.html' title='Февраль 2008'>Февраль 2008</a></li>
	<li><a href='../date/2007/12.html' title='Декабрь 2007'>Декабрь 2007</a></li>
	<li><a href='../date/2007/11.html' title='Ноябрь 2007'>Ноябрь 2007</a></li>
	<li><a href='../date/2007/10.html' title='Октябрь 2007'>Октябрь 2007</a></li>
	<li><a href='../date/2007/09.html' title='Сентябрь 2007'>Сентябрь 2007</a></li>
	<li><a href='../date/2007/08.html' title='Август 2007'>Август 2007</a></li>
	<li><a href='../date/2007/07/index.html' title='Июль 2007'>Июль 2007</a></li>
	<li><a href='../date/2007/06.html' title='Июнь 2007'>Июнь 2007</a></li>
	<li><a href='../date/2007/05.html' title='Май 2007'>Май 2007</a></li>
				</ul>
			</li>

			
					</ul>
	</div>

</div> <!-- wrapper -->
<div id="footer">
	<a href="../../feed">Entries (RSS)</a> and <a href="../../comments/feed">Comments (RSS)</a>. Valid <a href="http://validator.w3.org/check/referer" title="This page validates as XHTML 1.0 Transitional"><abbr title="eXtensible HyperText Markup Language">XHTML</abbr></a> and <a href="http://jigsaw.w3.org/css-validator/check/referer"><abbr title="Cascading Style Sheets">CSS</abbr></a>.<br />
	Powered by <a href="http://wordpress.org/" title="Powered by WordPress.">WordPress</a> and <a href="http://srinig.com/wordpress/themes/fluid-blue/">Fluid Blue theme</a>.<br />
	<!-- 15 queries. 0.103 seconds. -->
	</div>
</div> <!-- page -->
</body>
</html>
